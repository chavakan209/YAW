{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623bc624-833f-46b4-9390-4fc970177ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'LongLoRA' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/dvlab-research/LongLoRA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7165f9-61f5-47c2-9070-e53937c4de50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LongLoRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd LongLoRA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64540df0-2f4a-4a5e-b5c7-7f23b1e59983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers==4.34.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc326cc6-f5ed-4332-8e83-35d3e17bdcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da648bb-cfb1-4400-9e7f-4eaf3ebd9f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt\n",
    "!pip install -q flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "352474e5-4d48-4f93-aa94-712dd25bb1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19450950-1e8c-4436-8f3d-192f2a8a7b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 18 11:05:01 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   48C    P0              46W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          On  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   47C    P0              50W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          On  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   48C    P0              47W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          On  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   48C    P0              47W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80GB PCIe          On  | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   38C    P0              44W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80GB PCIe          On  | 00000000:00:0A.0 Off |                    0 |\n",
      "| N/A   42C    P0              48W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80GB PCIe          On  | 00000000:00:0B.0 Off |                    0 |\n",
      "| N/A   44C    P0              50W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80GB PCIe          On  | 00000000:00:0C.0 Off |                    0 |\n",
      "| N/A   40C    P0              43W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6796679e-1d2c-4d0f-aeb3-c988ad67a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae37136-1132-475b-975f-fbb9da81e904",
   "metadata": {},
   "source": [
    "**Supervised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c7c975-be0a-4315-b4a4-37c9a84a02a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting supervised-fine-tune.py\n"
     ]
    }
   ],
   "source": [
    "%%file supervised-fine-tune.py\n",
    "\n",
    "import io\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional, Sequence\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "from llama_attn_replace_sft import replace_llama_attn\n",
    "from gptneox_attn_replace import replace_gpt_neox_attn\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.distributed import barrier\n",
    "\n",
    "import os\n",
    "os.environ['WANDB_API_KEY'] = '401f903437fd6ca1d22e1d5685975c210605727a'\n",
    "os.environ['WANDB_PROJECT'] = 'YAWth'\n",
    "\n",
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "def _make_r_io_base(f, mode: str):\n",
    "    if not isinstance(f, io.IOBase):\n",
    "        f = open(f, mode=mode)\n",
    "    return f\n",
    "\n",
    "def jload(f = 'thanaphatt1/LongAlpaca-16kcontext-enth-and-WikiQA', mode=\"r\"):\n",
    "    \"\"\"Load a .json file into a dictionary.\"\"\"\n",
    "    dataset = load_dataset(f)\n",
    "    return dataset['train']\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input_llama2\":(\n",
    "        \"[INST] <<SYS>>\\n\"\n",
    "        \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\n\"\n",
    "        \"If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\"\n",
    "        \"<</SYS>> \\n\\n {instruction} [/INST]\"\n",
    "    ),\n",
    "    \"prompt_input_llama2\": (\n",
    "        \"[INST] <<SYS>>\\n\"\n",
    "        \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\n\"\n",
    "        \"If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\"\n",
    "        \"<</SYS>> \\n\\n {instruction} \\n{input} [/INST]\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    model_name_or_path: Optional[str] = field(default=\"EleutherAI/pythia-1.4b-deduped\")\n",
    "    model_type: Optional[str] = field(default=\"llama\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    data_path: str = field(default=None, metadata={\"help\": \"Path to the training data.\"})\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingArguments(transformers.TrainingArguments):\n",
    "    cache_dir: Optional[str] = field(default=None)\n",
    "    optim: str = field(default=\"adamw_torch\")\n",
    "    model_max_length: int = field(\n",
    "        default=8192 * 4,\n",
    "        metadata={\"help\": \"Maximum sequence length. Sequences will be right padded (and possibly truncated).\"},\n",
    "    )\n",
    "    use_flash_attn: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether use flash attention for training.\"},\n",
    "    )\n",
    "    use_full_attn: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether to use plain, full-attention for training.\"},\n",
    "    )\n",
    "    low_rank_training: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether use low rank adaptation for training.\"},\n",
    "    )\n",
    "    trainable_params: str = field(\n",
    "        default=\"embed,norm\",\n",
    "        metadata={\"help\": \"Additional trainable parameters except LoRA weights, if low rank training.\"},\n",
    "    )\n",
    "    neftune_noise_alpha=5\n",
    "    report_to='wandb'\n",
    "\n",
    "def smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict: Dict,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    model: transformers.PreTrainedModel,\n",
    "):\n",
    "    \"\"\"Resize tokenizer and embedding.\n",
    "\n",
    "    Note: This is the unoptimized version that may make your embedding size not be divisible by 64.\n",
    "    \"\"\"\n",
    "    num_new_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if num_new_tokens > 0:\n",
    "        input_embeddings = model.get_input_embeddings().weight.data\n",
    "        output_embeddings = model.get_output_embeddings().weight.data\n",
    "\n",
    "        input_embeddings_avg = input_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "        output_embeddings_avg = output_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "\n",
    "        input_embeddings[-num_new_tokens:] = input_embeddings_avg\n",
    "        output_embeddings[-num_new_tokens:] = output_embeddings_avg\n",
    "\n",
    "\n",
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = [\n",
    "        tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        for text in strings\n",
    "    ]\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        label[:source_len] = IGNORE_INDEX\n",
    "    return dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "\n",
    "class SupervisedDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer):\n",
    "        super(SupervisedDataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "        list_data_dict = jload('thanaphatt1/LongAlpaca-16kcontext-enth-and-WikiQA')\n",
    "\n",
    "        logging.warning(\"Formatting inputs...\")\n",
    "\n",
    "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input_llama2\"], PROMPT_DICT[\"prompt_no_input_llama2\"]\n",
    "        sources = [\n",
    "            prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n",
    "            for example in list_data_dict\n",
    "        ]\n",
    "\n",
    "        targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n",
    "\n",
    "        logging.warning(\"Tokenizing inputs... This may take some time...\")\n",
    "        data_dict = preprocess(sources, targets, tokenizer)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )\n",
    "\n",
    "\n",
    "def make_supervised_data_module(tokenizer: transformers.PreTrainedTokenizer, data_args) -> Dict:\n",
    "    \"\"\"Make dataset and collator for supervised fine-tuning.\"\"\"\n",
    "    train_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=data_args.data_path)\n",
    "    data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "    return dict(train_dataset=train_dataset, eval_dataset=None, data_collator=data_collator)\n",
    "\n",
    "\n",
    "def train():\n",
    "    parser = transformers.HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    # NOTE: May expand supported model types in the future\n",
    "    if model_args.model_type == \"gpt-neox\":\n",
    "        replace_gpt_neox_attn(training_args.use_flash_attn, training_args.use_full_attn)\n",
    "    else:\n",
    "        replace_llama_attn(training_args.use_flash_attn, training_args.use_full_attn)\n",
    "\n",
    "    # Set RoPE scaling factor\n",
    "    config = transformers.AutoConfig.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        cache_dir=training_args.cache_dir,\n",
    "    )\n",
    "\n",
    "    orig_rope_scaling = getattr(config, \"rope_scaling\", None)\n",
    "    if orig_rope_scaling is None:\n",
    "        orig_rope_scaling = {\"factor\": 1}\n",
    "    orig_rope_scaling_factor = orig_rope_scaling[\"factor\"] if \"factor\" in orig_rope_scaling.keys() else 1\n",
    "    orig_ctx_len = getattr(config, \"max_position_embeddings\", None)\n",
    "    if orig_ctx_len:\n",
    "        orig_ctx_len *= orig_rope_scaling_factor\n",
    "        if training_args.model_max_length > orig_ctx_len:\n",
    "            scaling_factor = float(math.ceil(training_args.model_max_length / orig_ctx_len))\n",
    "            config.rope_scaling = {\"type\": \"linear\", \"factor\": scaling_factor}\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        config=config,\n",
    "        cache_dir=training_args.cache_dir,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        cache_dir=training_args.cache_dir,\n",
    "        model_max_length=training_args.model_max_length,\n",
    "        padding_side=\"left\",\n",
    "        use_fast=True,\n",
    "    )\n",
    "\n",
    "    special_tokens_dict = dict()\n",
    "    if tokenizer.pad_token is None:\n",
    "        special_tokens_dict[\"pad_token\"] = DEFAULT_PAD_TOKEN\n",
    "    if tokenizer.eos_token is None:\n",
    "        special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "    if tokenizer.bos_token is None:\n",
    "        special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "    if tokenizer.unk_token is None:\n",
    "        special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "\n",
    "    smart_tokenizer_and_embedding_resize(\n",
    "        special_tokens_dict=special_tokens_dict,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    data_module = make_supervised_data_module(tokenizer=tokenizer, data_args=data_args)\n",
    "\n",
    "    if training_args.low_rank_training:\n",
    "        if model_args.model_type == \"gpt-neox\":\n",
    "            # added `dense` to match with llama as the basic LoRA would only target 'query_key_value'\n",
    "            targets = [\"query_key_value\", \"dense\"]\n",
    "        else:\n",
    "            targets=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "\n",
    "        config = LoraConfig(\n",
    "            r=8,\n",
    "            lora_alpha=16,\n",
    "            target_modules=targets,\n",
    "            lora_dropout=0,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        model = get_peft_model(model, config)\n",
    "        # enable trainable params\n",
    "        [p.requires_grad_() for n, p in model.named_parameters() if any([k in n for k in training_args.trainable_params.split(\",\")])]\n",
    "\n",
    "    model.config.use_cache = False         # required for gradient checkpointing\n",
    "    model.enable_input_require_grads()     # required for gradient checkpointing\n",
    "    model.gradient_checkpointing_enable()  # enable gradient checkpointing\n",
    "\n",
    "    trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args, **data_module)\n",
    "    trainer.train()\n",
    "    trainer.save_state()\n",
    "    trainer.save_model(output_dir=training_args.output_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a9696d-685a-4c06-887b-47b34c204785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.6)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.35.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.35.0-py2.py3-none-any.whl (248 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.40 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.35.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a4bdd-3a27-4b78-9e62-fab4e2c48bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-18 11:16:51,548] torch.distributed.run: [WARNING] \n",
      "[2023-11-18 11:16:51,548] torch.distributed.run: [WARNING] *****************************************\n",
      "[2023-11-18 11:16:51,548] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2023-11-18 11:16:51,548] torch.distributed.run: [WARNING] *****************************************\n",
      "[2023-11-18 11:16:57,622] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-11-18 11:16:57,850] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-11-18 11:16:57,861] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-11-18 11:16:57,865] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-11-18 11:16:57,872] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-11-18 11:16:57,873] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-11-18 11:16:57,889] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-11-18 11:16:57,911] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-11-18 11:16:57,968] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2023-11-18 11:16:58,192] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2023-11-18 11:16:58,192] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2023-11-18 11:16:58,202] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2023-11-18 11:16:58,209] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2023-11-18 11:16:58,215] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2023-11-18 11:16:58,244] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2023-11-18 11:16:58,265] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2023-11-18 11:16:58,278] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.84s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.96s/it]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.97s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  6.00s/it]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.85s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.84s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.88s/it]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.76s/it]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "WARNING:root:Loading data...\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "WARNING:root:Formatting inputs...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "WARNING:root:Formatting inputs...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "WARNING:root:Formatting inputs...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "WARNING:root:Formatting inputs...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "WARNING:root:Formatting inputs...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "WARNING:root:Formatting inputs...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "WARNING:root:Formatting inputs...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "WARNING:root:Formatting inputs...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=8 supervised-fine-tune.py  \\\n",
    "        --model_name_or_path openthaigpt/openthaigpt-1.0.0-beta-7b-chat-ckpt-hf \\\n",
    "        --bf16 True \\\n",
    "        --output_dir ckpt_YAW2 \\\n",
    "        --model_max_length 16000 \\\n",
    "        --use_flash_attn True \\\n",
    "        --data_path thanaphatt1/LongAlpaca-16kcontext-enth-and-WikiQA\\\n",
    "        --low_rank_training True \\\n",
    "        --num_train_epochs 3  \\\n",
    "        --per_device_train_batch_size 1    \\\n",
    "        --gradient_accumulation_steps 4     \\\n",
    "        --evaluation_strategy \"no\"     \\\n",
    "        --save_strategy \"epoch\"     \\\n",
    "        --save_total_limit 1     \\\n",
    "        --learning_rate 2e-5     \\\n",
    "        --weight_decay 0.0     \\\n",
    "        --warmup_steps 20     \\\n",
    "        --lr_scheduler_type \"constant_with_warmup\"     \\\n",
    "        --logging_steps 10     \\\n",
    "        --deepspeed \"ds_configs/stage2.json\" \\\n",
    "        --tf32 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2f6a95e-e215-457b-a0e8-8628da1ebb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LongLoRA/ckpt_YAW2/checkpoint-2232\n"
     ]
    }
   ],
   "source": [
    "cd ckpt_YAW2/checkpoint-2232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15165c1a-71f0-42de-810f-05c203f05d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-19 00:19:40,418] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Processing zero checkpoint './global_step2232'\n",
      "Detected checkpoint of type zero stage 2, world_size: 8\n",
      "Parsing checkpoint created by deepspeed==0.12.3\n",
      "Reconstructed Frozen fp32 state dict with 225 params 6707650560 elements\n",
      "Reconstructed fp32 state dict with 322 params 240300032 elements\n",
      "Saving fp32 state dict to pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!python3 zero_to_fp32.py . pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b4b117f-ade6-49f9-b105-995575a164d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LongLoRA\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/LongLoRA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75f626e7-52f7-41a9-9385-2f0fdcbf2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 get_trainable_weights.py --checkpoint_path ckpt_YAW2/checkpoint-2232 --trainable_params \"embed,norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd83ef-1ea0-402b-9383-d2268c66754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model openthaigpt/openthaigpt-1.0.0-beta-7b-chat-ckpt-hf\n",
      "peft model ckpt_YAW2/checkpoint-2232\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "!python3 merge_lora_weights_and_save_hf_model.py \\\n",
    "        --base_model openthaigpt/openthaigpt-1.0.0-beta-7b-chat-ckpt-hf  \\\n",
    "        --peft_model ckpt_YAW2/checkpoint-2232 \\\n",
    "        --context_size 16000 \\\n",
    "        --save_path YAW_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c0d34-687b-4cfa-a3d4-dc7893771de3",
   "metadata": {},
   "source": [
    "**Demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0a796f3-caa6-4b40-b5b0-d0bae14ca740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb97fc33faa4b6da016ba2639c4c367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b410f8cbe04e1bac8c25d38bebec79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        'YAW_model2',\n",
    "        cache_dir=\"cacheDir\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map={\"\": 0},\n",
    "    )\n",
    "tokenizer = LlamaTokenizer.from_pretrained('YAW_model2')\n",
    "tokenizer.padding_side = \"left\" \n",
    "\n",
    "model_OPT = AutoModelForCausalLM.from_pretrained(\n",
    "        'openthaigpt/openthaigpt-1.0.0-beta-7b-chat-ckpt-hf',\n",
    "        cache_dir=\"cacheDir\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map={\"\": 0},\n",
    "    )\n",
    "tokenizer_OPT = LlamaTokenizer.from_pretrained('openthaigpt/openthaigpt-1.0.0-beta-7b-chat-ckpt-hf')\n",
    "tokenizer_OPT.padding_side = \"left\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0face-d876-4405-9e8b-07122caf0adf",
   "metadata": {},
   "source": [
    "**LlamaGeneerate code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a855722a-7f81-4fc1-9d0f-d1cb7e39ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "def cut_off_text(text, prompt):\n",
    "    cutoff_phrase = prompt\n",
    "    index = text.find(cutoff_phrase)\n",
    "    if index != -1:\n",
    "        return text[:index]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_substring(string, substring):\n",
    "    return string.replace(substring, \"\")\n",
    "\n",
    "\n",
    "\n",
    "def generate(instruction, input):\n",
    "    prompt = f\"\"\"[INST] <<SYS>>\\n\n",
    "        You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\n\n",
    "        If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\n",
    "        <</SYS>> \\n\\n {instruction}\\n{input} [/INST]\"\"\"\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 # temperature=0.1,\n",
    "                                 eos_token_id=tokenizer.eos_token_id,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 repetition_penalty=1.2,\n",
    "                                 top_p =0.75,\n",
    "                                 top_k = 70,\n",
    "                                 no_repeat_ngram_size = 4,\n",
    "                                 )\n",
    "        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        final_outputs = cut_off_text(final_outputs, '</s>')\n",
    "        final_outputs = final_outputs.split('[/INST]')[1]\n",
    "\n",
    "    return final_outputs#, outputs\n",
    "\n",
    "def generate_OPT(instruction, input):\n",
    "    prompt = f\"\"\"{instruction}\"\"\"\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        inputs = tokenizer_OPT(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        outputs = model_OPT.generate(**inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 # temperature=0.1,\n",
    "                                 eos_token_id=tokenizer.eos_token_id,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 repetition_penalty=1.2,\n",
    "                                 top_p =0.75,\n",
    "                                 top_k = 70,\n",
    "                                 no_repeat_ngram_size = 4,\n",
    "                                 )\n",
    "        final_outputs = tokenizer_OPT.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    return final_outputs#, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3ed2e6a1-688f-460b-ad41-454e67a7c390",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m instruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mด้านล่างเป็นข้อมูล จำข้อมูลและตอบคำถามของฉันหลังข้อมูล ข้อมูลเริ่มต้นขึ้น Abstract DETR รุ่น DEtection TRansformer ล่าสุดได้รับประสิทธิภาพที่โดดเด่น ความสำเร็จไม่สามารถเกิดขึ้นได้หากปราศจากการนำฟีเจอร์ฟิวชั่นหลายขนาดในตัวเข้ารหัสกลับมาใช้ใหม่: อย่างไรก็ตาม; โทเค็นที่เพิ่มขึ้นมากเกินไปในฟีเจอร์หลายสเกล โดยเฉพาะฟีเจอร์ระดับต่ำประมาณ 759 รายการนั้นไม่มีประสิทธิภาพในการคำนวณ ซึ่งค่อนข้างเป็นอุปสรรคต่อการใช้งานจริงของแบบจำลอง DETR ในบทความนี้ เรานำเสนอ Lite DETR ซึ่งเป็นเฟรมเวิร์กการตรวจจับวัตถุแบบ end-to-end ที่เรียบง่ายแต่ทรงประสิทธิภาพ ซึ่งสามารถลด GFLOP ของส่วนหัวการตรวจจับได้อย่างมีประสิทธิภาพถึง 60\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m ในขณะที่ยังคงรักษาประสิทธิภาพดั้งเดิมไว้ 99\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m โดยเฉพาะ; เราออกแบบบล็อกตัวเข้ารหัสที่มีประสิทธิภาพเพื่ออัปเดตคุณสมบัติระดับสูง (สอดคล้องกับแผนที่คุณสมบัติความละเอียดขนาดเล็ก) และคุณสมบัติระดับต่ำ (สอดคล้องกับแผนที่คุณสมบัติความละเอียดสูงในลักษณะแทรกสลับ นอกจากนี้ เพื่อหลอมรวมคุณสมบัติข้ามสเกลได้ดีขึ้น เราพัฒนาความสนใจที่เปลี่ยนรูปได้โดยการรับรู้คีย์เพื่อคาดการณ์น้ำหนักความสนใจที่เชื่อถือได้มากขึ้น การทดลองที่ครอบคลุมจะตรวจสอบประสิทธิภาพและประสิทธิภาพของ Lite DETR ที่เสนอ และกลยุทธ์ตัวเข้ารหัสที่มีประสิทธิภาพสามารถสรุปได้ดีในโมเดลที่ใช้ DETR ที่มีอยู่: รหัสที่พร้อมใช้งานจะเป็น IDEA-Research /Lite ใน https / /github _ com DETR รูปที่ 1 แกนความแม่นยำเฉลี่ย) เทียบกับ GFLOP (แกน X) สำหรับการฝึกอบรมข้อมูลโมเดลการตรวจจับที่แตกต่างกันบน COCO โดยไม่ต้องเพิ่มเติม ทุกรุ่นยกเว้น EfficientDet [29] และ YOLO ซีรีส์ [12,30] ใช้ Tiny เป็นแบ็คโบน โดยเฉพาะเครื่องหมายสองตัว ResNet-50 และ Swin- Tiny; ตามลำดับ: ในบรรทัดเดียวกันให้ใช้ ResNet-50 และ Swin- In เครื่องหมายแยกใช้เฉพาะ ResNet-50_ แต่ละเส้นประเชื่อมต่อการเพิ่มตัวแปรอัลกอริทึมก่อนและหลังอัลกอริทึม ขนาดรุ่นที่ระบุไว้ของเราแตกต่างกันไปตั้งแต่ 32M ถึง 82M: เมื่อเร็วๆ นี้ DEtection TRansformer [1] DETR แนะนำ Transformers ในการตรวจจับวัตถุ และโมเดลที่คล้าย DETR ได้รับประสิทธิภาพที่คาดหวังในงานวิชันพื้นฐานหลายอย่าง เช่น การตรวจจับวัตถุ [13,36,37] การแบ่งส่วนอินสแตนซ์ [5,6,14] และก่อให้เกิดการประมาณค่า [26,28] 1. บทนำ ตามแนวคิด DETR [1] ประกอบด้วยสามส่วน: กระดูกสันหลัง ตัวเข้ารหัส Transformer; และงานวิจัยของ Transformer de Many ได้ปรับปรุง back coder: กระดูกและชิ้นส่วนตัวถอดรหัส ตัวอย่างเช่น กระดูกสันหลังใน DETR โดยปกติจะสืบทอดมาและได้รับประโยชน์อย่างมากจากแบบจำลองการจำแนกประเภทที่ผ่านการฝึกอบรมมาแล้ว 10, 20]: ส่วนตัวถอดรหัสใน DETR เป็นจุดสนใจในการวิจัยหลัก โดยมีงานวิจัยจำนวนมากที่พยายามแนะนำโครงสร้างที่เหมาะสมให้กับแบบสอบถาม DETR และฉันกำลังพิสูจน์อยู่ ประสิทธิภาพการฝึก 11,13,18,21,36,37]. โดยคอน การตรวจจับวัตถุมีจุดมุ่งหมายเพื่อตรวจจับวัตถุที่น่าสนใจในยุคของภาพโดยจำกัดกรอบขอบเขตของมันและคาดการณ์ ในทศวรรษที่ผ่านมา คะแนนการจำแนกประเภทที่เกี่ยวข้องกันมีความก้าวหน้าอย่างเห็นได้ชัดได้ถูกสร้างขึ้นโดยโมเดล de tection แบบคลาสสิกจำนวนมาก [23, 24] บนเครือข่ายแบบ convolutional Feng งานนี้เกิดขึ้นเมื่อ Li ฝึกงานที่ IDEA โทเค็นดั้งเดิมที่คำนวณได้จำนวนมากและบันทึกที่ส่วนท้ายของบล็อกตัวเข้ารหัส เราปล่อยให้ต้นทุนในระดับต่ำ: kens ค้นหาแผนที่คุณลักษณะทั้งหมดเพื่ออัปเดตการเป็นตัวแทน ดังนั้น จึงรักษาคุณลักษณะหลายขนาดไว้ ในคุณลักษณะระดับสูงและระดับต่ำที่สอดแทรกในลักษณะที่แตกต่างกัน เราอัปเดตความถี่เพื่อการคำนวณที่มีประสิทธิภาพ จริงอยู่ งานน้อยลงมากแล้ว t0 ปรับปรุงส่วนตัวเข้ารหัส: ตัวเข้ารหัสในวานิลลา DETR มีเลเยอร์ Transformer หกชั้น ตัวเข้ารหัสซ้อนกันที่ด้านบนของกระดูกสันหลังเพื่อปรับปรุง เมื่อเปรียบเทียบกับแบบจำลองการตรวจจับแบบคลาสสิก มันขาดคุณสมบัติหลายขนาด ซึ่ง มีความสำคัญอย่างมากต่อการตรวจจับวัตถุ โดยเฉพาะอย่างยิ่งสำหรับการตรวจจับวัตถุขนาดเล็ก [9,16,19,22,29] การใช้เลเยอร์ Transformer en coder บนคุณสมบัติหลายขนาดนั้นไม่สามารถใช้งานได้จริง เนื่องจากต้นทุนการคำนวณที่ห้ามปรามซึ่งเป็นกำลังสองของจำนวนโทเค็นคุณสมบัติ ตัวอย่างเช่น DETR ใช้แผนผังคุณสมบัติ C5 ซึ่งเป็น 1/32 ของความละเอียดภาพอินพุต เพื่อใช้ตัวเข้ารหัส Transformer: หากรวมคุณสมบัติ C3 (สเกล 1/8) ไว้ในคุณสมบัติหลายสเกล จำนวนโทเค็นจากสเกลนี้เพียงอย่างเดียวจะเป็น 16 เท่าของโทเค็นจากต้นทุนการคำนวณของการเอาใจใส่ตนเองใน แผนผังคุณลักษณะ C5 หม้อแปลงไฟฟ้าจะสูง 256 เท่า: นอกจากนี้; เพื่อปรับปรุงคุณลักษณะระดับต่ำที่ล่าช้า up-key-aware deformable Attention (KDA) เราเสนอแนวทางในการแทนที่เลเยอร์ความสนใจทั้งหมด เมื่อดำเนินการให้ความสนใจที่เปลี่ยนรูปได้สำหรับแต่ละแบบสอบถาม โดยจะสุ่มตัวอย่างทั้งคีย์และค่าจากตำแหน่งการสุ่มตัวอย่างเดียวกันในแผนผังคุณลักษณะ จากนั้น จะสามารถคำนวณน้ำหนักความสนใจที่เชื่อถือได้มากขึ้นโดยการเปรียบเทียบแบบสอบถามกับคีย์ตัวอย่าง: วิธีการดังกล่าวยังถือได้ว่าเป็นความสนใจหนาแน่นแบบกระจัดกระจายแบบขยายที่ปรับเปลี่ยนรูปแบบได้ ความสนใจ หรือ เราพบว่า KDA มีประสิทธิภาพมากในการนำประสิทธิภาพกลับคืนมาด้วยบล็อกตัวเข้ารหัสที่มีประสิทธิภาพที่เสนอ: กับเรา เพื่อแก้ไขปัญหานี้ DETR ที่เปลี่ยนรูปได้ [37] พัฒนาอัลกอริธึมความสนใจที่ปรับรูปได้เพื่อลดความซับซ้อนของความสนใจในการดำเนินการด้วยตนเองจากกำลังสองเป็นเชิงเส้นโดยการเปรียบเทียบโทเค็นการสืบค้นแต่ละรายการด้วยจำนวนจุดสุ่มตัวอย่างคงที่เท่านั้น จากการคำนวณการเอาใจใส่ตนเองที่มีประสิทธิภาพนี้ DETR ที่เปลี่ยนรูปได้แนะนำคุณสมบัติหลายสเกลให้กับ DETR_ และตัวเข้ารหัสที่เปลี่ยนรูปได้ถูกนำมาใช้กันอย่างแพร่หลายในรุ่นที่คล้าย DETR ต่อมา 11,13,18,36] สรุปการมีส่วนร่วมของเรามีดังนี้_ เราเสนอบล็อกตัวเข้ารหัสที่มีประสิทธิภาพเพื่ออัปเดตคุณสมบัติระดับสูงและระดับต่ำในลักษณะแทรกซึม ลดโทเค็นคุณลักษณะลงอย่างมากซึ่งสามารถตรวจจับได้อย่างมีประสิทธิภาพ ตัวเข้ารหัสนี้สามารถเสียบเข้ากับรุ่นที่ใช้ DETR ที่มีอยู่ได้อย่างง่ายดาย เพื่อปรับปรุงการอัปเดตคุณสมบัติที่ล่าช้า เราแนะนำความสนใจที่เปลี่ยนรูปได้โดยการรับรู้คีย์เพื่อการทำนายน้ำหนักความสนใจที่เชื่อถือได้มากขึ้น: การทดลองที่ครอบคลุมแสดงให้เห็นว่า Lite DETR สามารถลด GFLOP ของหัวตรวจจับได้ 60\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m และประสิทธิภาพการตรวจจับหลัก 99\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m โดยเฉพาะอย่างยิ่ง Lite- DINO-SwinT ของเรามี AP 53.9 พร้อมด้วย 159 GFLOP โทเค็นการสืบค้นจำนวนมากแนะนำอย่างไรก็ตาม; เนื่องจากเกิดจากคุณสมบัติหลายขนาด ตัวเข้ารหัสที่เปลี่ยนรูปได้จึงมีต้นทุนการคำนวณสูง เพื่อเผยให้เห็นว่าสิ่งนี้ยังคงประสบปัญหาจากการทดลองเชิงวิเคราะห์ตามที่แสดงปัญหา เราดำเนินการ 2 รายการโดยใช้โมเดล DINO [36] ที่ใช้ DETR ในตารางและวิเคราะห์คอขวดของประสิทธิภาพของคุณสมบัติหลายขนาด_ สามารถสังเกตผลลัพธ์ที่น่าสนใจบางประการได้ อันดับแรก; คุณลักษณะระดับต่ำ (แผนที่ความละเอียดสูง) คิดเป็นสัดส่วนมากกว่า 75\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m ของโทเค็นทั้งหมด ประการที่สอง การลดคุณสมบัติระดับต่ำลงโดยตรง (สเกล DINO-3) ส่วนใหญ่ส่งผลต่อประสิทธิภาพการตรวจจับสำหรับวัตถุขนาดเล็ก (AP_S) ลดลง 10\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m แต่ส่งผลกระทบเพียงเล็กน้อยกับวัตถุขนาดใหญ่ (AP_L) 2. งานที่เกี่ยวข้อง เบื้องต้น: DETR [1] ถือว่าการตรวจจับวัตถุเป็นปัญหาการทำนายโดยตรง และใช้การสูญเสียทั่วโลกกับการทำนายแรงชุดตามชุดผ่านการจับคู่แบบสองฝ่าย: Vanilla DETR [1] ใช้เฉพาะคุณสมบัติระดับเดียวจากขั้นตอนที่ 3 สุดท้ายของอิมเมจอินพุต ความละเอียด) เช่น ของแบ็คโบน Xfeat RNx D โดยที่ Dis คือมิติฟีเจอร์และ N คือจำนวนฟีเจอร์ที่ราบเรียบทั้งหมด คุณสมบัติเหล่านี้จะถูกประมวลผลโดยตัวเข้ารหัสที่มีเลเยอร์การเอาใจใส่ตนเองหนาแน่นสำหรับการหลอมรวมและการปรับปรุงคุณสมบัติ: การใช้ 16 ] ในตัวเข้ารหัสโมเดลที่ใช้ CNN นั้นคล้ายคลึงกับ FPN คุณสมบัติที่ได้รับการปรับปรุงเหล่านี้จะถูกสอบถามโดยตัวถอดรหัสเพื่อตรวจจับวัตถุโดยการทำนายคะแนนการจำแนกประเภทและกล่องขอบเขตแบบถดถอย โดยทั่วไป เนื่องจาก DETR ใช้เฉพาะคุณสมบัติระดับสูงที่มีความละเอียดต่ำ คุณสมบัติเหล่านี้จึงขาดรายละเอียดภายในเครื่องที่สมบูรณ์ซึ่งมีความสำคัญต่อการตรวจจับวัตถุขนาดเล็ก ด้วยแรงบันดาลใจจากข้อสังเกตข้างต้น เรากระตือรือร้นที่จะตอบคำถาม: เราจะใช้มาตราส่วนฟีเจอร์น้อยลงแต่ยังคงรักษารายละเอียดที่สำคัญในท้องถิ่นไว้ได้หรือไม่ เรานำเสนอเฟรม DETR ที่มีประสิทธิภาพ โดยใช้ประโยชน์จากคุณสมบัติหลายสเกลที่มีโครงสร้าง โดยเฉพาะอย่างยิ่ง เราออกแบบงานที่เรียบง่าย ชื่อ Lite DETR รวมถึงเลเยอร์การใส่ใจในตัวเองของบล็อกตัวเข้ารหัสที่เปลี่ยนรูปได้แต่มีประสิทธิภาพ เป็นแบบพลักแอนด์เพลย์ในรุ่นฐาน DETR หลายขนาดที่สามารถลด GFLOP ของตัวเข้ารหัสได้ 62\u001b[39m\u001b[38;5;132;01m% 78%\u001b[39;00m\u001b[38;5;124m และรักษาประสิทธิภาพการแข่งขัน บล็อกตัวเข้ารหัสแบ่งคุณสมบัติหลายสเกลออกเป็น C6,C5,C4 ระดับสูง) และคุณสมบัติระดับต่ำ (เช่น (เช่น คุณสมบัติ C3)_ คุณสมบัติระดับสูงและระดับต่ำจะได้รับการอัปเดตในลักษณะแทรกสลับ เพื่อปรับปรุงพีระมิดฟีเจอร์หลายขนาด นั่นคือในสองสามเลเยอร์แรก เราปล่อยให้ฟีเจอร์ระดับสูงค้นหาแผนผังฟีเจอร์ทั้งหมดและปรับปรุงการนำเสนอ แต่ยังคงรักษาโทเค็นระดับต่ำไว้: กลยุทธ์ดังกล่าวสามารถลดจำนวนได้อย่างมีประสิทธิภาพ ของโทเค็นการสืบค้นถึง 5\u001b[39m\u001b[38;5;132;01m% 25%\u001b[39;00m\u001b[38;5;124m ของ การปรับปรุงการออกแบบตัวถอดรหัสของ DETR: เมื่อเร็วๆ นี้ เครื่องตรวจจับที่ใช้ DETR มีความก้าวหน้าที่รวดเร็วกว่า 13,18,21,33, 36] เมื่อเปรียบเทียบกับเครื่องตรวจจับแบบคลาสสิก [2,24] ผลที่ตามมา; DINO [36] คว้าอันดับหนึ่งในการตรวจจับวัตถุ COCO 2017 สำหรับโมเดลที่คล้าย DETR ครั้งแรกที่งานส่วนใหญ่เน้น ตารางที่ 1 GFLOP ของ DINO ที่ใช้ ResNet-50 โดยมีฟีเจอร์สเกล 4 สเกลและฟีเจอร์สเกล 3 สเกล ตามลำดับ: เราใช้ ResNet-50 เป็นแกนหลักและประเมิน COCO val2017 ที่ได้รับการฝึก 12 ยุค 100\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m หมายความว่าเราใช้โทเค็นฟีเจอร์ทั้งหมด ในขณะที่ 25\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m หมายความว่าเราใช้ฟีเจอร์ระดับสูงสามฟีเจอร์ซึ่งคิดเป็น 25\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m ของโทเค็นทั้งหมด_ ปรับปรุงตัวถอดรหัส Transformer ใน DETR เพื่อประสิทธิภาพที่ดีขึ้นและความเร็วการบรรจบกันที่เร็วขึ้น โดยเฉพาะตำแหน่ง Meng และคณะ [21 เสนอให้แยกเนื้อหาและข้อมูลในตัวถอดรหัสเพื่อให้มีลำดับความสำคัญเชิงพื้นที่ที่ดีขึ้นในการแปลเป็นภาษาท้องถิ่น [18, 37] ออกแบบสูตรการสืบค้นตำแหน่งที่ดีกว่างานก่อนหน้านี้ รูปแบบการกำหนดป้ายกำกับแบบตัวต่อตัวยังถูกกล่าวถึงอย่างกว้างขวางในการมอบหมาย [4,11,13,36] ยิ่งไปกว่านั้น การออกแบบให้ดีขึ้นสำหรับบางรุ่น [33,36,37] การเริ่มต้นคิวรีตัวถอดรหัสที่ดีกว่าโดยใช้ Priors ที่หนาแน่นจากตัวเข้ารหัส: ตารางที่ 2 อัตราส่วนโทเค็นของแต่ละสเกลฟีเจอร์ในพีระมิดฟีเจอร์ 4 สเกล 3. วิธีการ 3.1. แรงจูงใจและการวิเคราะห์ ในส่วนนี้ ก่อนอื่นเราจะวิเคราะห์ว่าทำไมโมเดลที่น่าสนใจที่ใช้ DETR ที่มีอยู่จึงยังคงไม่มีประสิทธิภาพ จากนั้นจึงแสดงคุณลักษณะหลายสเกลบางอย่างที่มีความสำคัญอย่างยิ่งต่อการสังเกต โดยจะตรวจจับวัตถุที่มีสเกลที่หลากหลาย ประกอบด้วยคุณสมบัติหลายระดับตั้งแต่คุณสมบัติระดับสูง (ความละเอียดต่ำ) ไปจนถึงคุณสมบัติระดับต่ำ (ความละเอียดสูง) โทเค็นระดับล่างแต่ละอันที่มากกว่าแผนผังคุณสมบัติก่อนหน้านี้มีระดับ ture 4 เท่า_ จากตารางที่ 2 เราสามารถสังเกตได้ว่าจำนวนโทเค็นในคุณสมบัติระดับต่ำเพิ่มขึ้นเป็นสองเท่า ในขณะที่สามระดับที่สูงกว่าคิดเป็นประมาณ 25\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m เท่านั้น . การปรับปรุงการแยกคุณสมบัติหลายระดับของ DETR: แม้ว่าโมเดลที่ใช้ DETR พร้อมฟีเจอร์หลายสเกลจะแสดงประสิทธิภาพที่น่าหวัง [36, 37] โดยเฉพาะอย่างยิ่งสำหรับการตรวจจับวัตถุขนาดเล็ก ประสิทธิภาพยังคงเป็นข้อกังวลสำหรับการใช้งานจำนวนมาก ในความเป็นจริง การแยกคุณสมบัติหลายระดับได้รับการศึกษาประสิทธิภาพอย่างกว้างขวางในเครื่องตรวจจับที่ใช้ CNN จำนวนมากสำหรับและประสิทธิผล เช่น FPN 16], BiFPN [29], PANET [19] และ NAS-FPN [9] แต่ประสิทธิภาพ ของ DETR หลายระดับยังไม่ได้รับการสำรวจ เมื่อเร็ว ๆ นี้ มีผลงานบางส่วน [27,34,35, 37] ได้ลองใช้ตัวเข้ารหัสที่มีประสิทธิภาพในการออกแบบ t0 นอกจากนี้ เรายังนำตัวแปร DETR DINO [36] เป็นตัวอย่างเบื้องต้นอีกด้วย จะเกิดอะไรขึ้นหากเราทิ้งคุณลักษณะระดับต่ำ (S4 ในตารางที่ 2) ลงในตัวเข้ารหัสที่เปลี่ยนรูปได้เพื่อลดต้นทุนในการคำนวณ ในตารางที่ 1 ประสิทธิภาพที่ลดลงของโมเดล DINO-3scale แลกกับ 48 \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m ในแง่ได้รับความแม่นยำเฉลี่ย (AP) ของ GFLOP 4.99 ที่ราคา และแม้แต่ 10.2\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m AP สำหรับการตรวจจับวัตถุขนาดเล็ก การเสื่อมสภาพ_ วัตถุมีการแข่งขัน ใหญ่ นั่นคือ อย่างไรก็ตาม; AP บนโทเค็นระดับสูงประกอบด้วยข้อมูลที่กะทัดรัดและความหมายที่หลากหลายเพื่อตรวจจับวัตถุส่วนใหญ่ ตรงกันข้าม; โทเค็นระดับต่ำจำนวนมากมีหน้าที่หลักในรายละเอียดท้องถิ่นเพื่อตรวจจับวัตถุขนาดเล็ก ในขณะเดียวกัน คุณลักษณะหลายขนาดประกอบด้วยโทเค็นที่ซ้ำซ้อนจำนวนมาก โดยเฉพาะคุณลักษณะระดับต่ำ ดังนั้น เราจึงต้องการสำรวจวิธีการอัปเดตคุณลักษณะหลายขนาดอย่างมีประสิทธิภาพโดยเน้นไปที่การสร้างคุณลักษณะระดับสูงที่ดีขึ้นเป็นหลัก: DETR ที่เปลี่ยนรูปได้ [37] เสนอความสนใจที่เปลี่ยนรูปได้ ซึ่งสามารถใช้ในตัวเข้ารหัส DETR t0 กระจายค่าในชั้นการเอาใจใส่ตนเองโดยการสุ่มตัวอย่างเพียงไม่กี่ค่าสำหรับแต่ละแบบสอบถาม ข้อเสนอที่เปลี่ยนรูปได้coder นำไปสู่ผลลัพธ์การตรวจจับด้วยต้นทุนการคำนวณที่ไม่แพง ซึ่งเป็นที่ยอมรับอย่างกว้างขวางและนำไปใช้ในงานวิชั่นมากมาย อย่างไรก็ตาม; เมื่อเปรียบเทียบกับเครื่องตรวจจับขนาดเดียว ค่าใช้จ่ายในการคำนวณของ DETR ที่เปลี่ยนรูปได้หลายขนาดยังคงสูงสำหรับการใช้งานที่มีประสิทธิภาพ โดยอาศัยตัวเข้ารหัสที่เปลี่ยนรูปได้ที่แข็งแกร่ง งานบางชิ้นพยายามปรับปรุงประสิทธิภาพ DETR ที่มีประสิทธิภาพ [33] เสนอให้ใช้เลเยอร์ตัวเข้ารหัสน้อยลงโดยใช้ประโยชน์จากไพรเออร์หนาแน่นของตัวเข้ารหัสสำหรับการเริ่มต้นการสืบค้นตัวถอดรหัส Sparse DETR [25] เสนอให้อัปเดตโทเค็นหลักอย่างกระจัดกระจายในตัวเข้ารหัสเพื่อลดจำนวนการสืบค้นด้วยเครือข่ายการให้คะแนน: ในความเป็นจริง ตัวเข้ารหัสมีหน้าที่รับผิดชอบในการแยกคุณสมบัติ แต่ Sparse DETR แนะนำการสูญเสียการตรวจจับหลายชั้นในเลเยอร์ตัวเข้ารหัส ทำให้ ยากที่จะสรุปกับรุ่นที่ใช้ DETR อื่น ๆ จัดลำดับความสำคัญการอัปเดตคุณสมบัติระดับสูงในลักษณะนี้ เราสามารถเลเยอร์ซึ่งสามารถลดโทเค็นการสืบค้นได้อย่างมากสำหรับตัวเข้ารหัสหลายสเกลที่มีประสิทธิภาพมากขึ้น: โดยสรุป งานนี้ออกแบบโซลูชันทั่วไปสำหรับ DETR ที่มีประสิทธิภาพสูง มีวัตถุประสงค์เพื่อใช้เครื่องตรวจจับและรักษาประสิทธิภาพการแข่งขัน เมื่อเร็วๆ นี้ DETR++ [34] เสนอ t0 แทนที่ตัวเข้ารหัสด้วย BiFPN [29] และ VIDT [27] พัฒนาตัวถอดรหัสที่แข็งแกร่งกว่าเพื่อลบตัวเข้ารหัส: IMFA [35] เสนอตัวอย่างพื้นที่ที่น่าสนใจกระจัดกระจายของคุณสมบัติแบบปรับได้หลายขนาดจากบางส่วน อย่างไรก็ตาม ; ประสิทธิภาพของคุณสมบัติมาตราส่วนแบบจำลองเหล่านี้_ ยังคงล้าหลังส่วนใหญ่จากเครื่องตรวจจับที่ได้รับการปรับปรุง 13,36] ตามตัวเข้ารหัสที่เปลี่ยนรูปได้: 3.2. ภาพรวมโมเดล ตาม DETR ที่เปลี่ยนรูปได้หลายสเกล [37] Lite DETR ประกอบด้วยกระดูกสันหลัง ซึ่งเป็นตัวเข้ารหัสหลายชั้น ตัวถอดรหัสหลายชั้นพร้อมหัวทำนาย กรอบงานโดยรวมและแบบจำลองจะแสดงในรูปที่ 2 โดยเฉพาะ เราแยกกัน รูปที่ 2 ภาพประกอบของเฟรมเวิร์ก Lite DETR เราใช้ S2 S4 เพื่อระบุคุณสมบัติจากสเตจแบ็คโบนที่แตกต่างกัน นั่นคือ C3 ใน ResNet-50 [10] S1 ได้มาจากการลดขนาด Cs เพิ่มเติมด้วยอัตราส่วน 0.5 ในรูปนี้ เราใช้ S1 S3 ซึ่งสอดคล้องกับคุณลักษณะระดับสูงของ C5 เป็นตัวอย่าง นอกจากนี้; (a) คือการอัปเดตฟีเจอร์ระดับสูงที่นำเสนอซึ่งกล่าวถึงใน Sec. 3.4 และ (b) เป็นคุณลักษณะระดับต่ำฟิวชั่นข้ามสเกลที่กล่าวถึงในวินาที 3.5. ในแต่ละบล็อกตัวเข้ารหัสที่มีประสิทธิภาพ คุณลักษณะหลายขนาดจะผ่านคุณลักษณะระดับสูง A ครั้ง จากนั้นจึงดำเนินการอัปเดตคุณลักษณะระดับต่ำที่ส่วนท้ายของแต่ละบล็อก: บล็อกตัวเข้ารหัสที่มีประสิทธิภาพจะดำเนินการอัปเดต B ครั้ง_ สำหรับ 3.4. ฟิวชั่นข้ามสเกลคุณสมบัติระดับสูงซ้ำ คุณสมบัติหลายระดับตั้งแต่แกนหลักไปจนถึงคุณสมบัติระดับสูงและคุณสมบัติระดับต่ำ คุณสมบัติเหล่านี้จะได้รับการอัปเดตโดยมีความแตกต่างในลักษณะที่มีการสลับกัน (แนะนำในมาตรา 3.3 การอัปเดตความถี่ (อธิบายในมาตรา 3.4 และ 3.5 ในบล็อกตัวเข้ารหัสที่มีประสิทธิภาพที่นำเสนอเพื่อให้ได้ความแม่นยำและการแลกเปลี่ยนประสิทธิภาพ เพื่อปรับปรุงการอัปเดตที่ล่าช้าของ คุณลักษณะระดับต่ำ เรายังแนะนำความสนใจแนวทาง KDA ที่เปลี่ยนรูปแบบการรับรู้คีย์เพิ่มเติม) ที่อธิบายไว้ในมาตรา 3.6) ในโมดูลนี้ คุณลักษณะระดับสูง FH จะทำหน้าที่เป็นแบบสอบถาม (Q) เพื่อแยกคุณลักษณะจากทุกระดับ รวมถึงโทเค็นคุณลักษณะระดับต่ำและระดับสูง การดำเนินการนี้ช่วยเพิ่มการแสดง FH ด้วยทั้ง se mantics ระดับสูงและรายละเอียดที่มีความละเอียดสูง การอัปเดตโดยละเอียด การดำเนินการนี้มีประสิทธิภาพสูง ดังแสดงในรูปที่ 2(a) ใช้ ficient. การสืบค้นคุณลักษณะแบบหลายสเกลใน ตัวอย่างเช่น สองสเกลแรกหรือสามสเกลแรกอย่างมีนัยสำคัญจะลดการสืบค้น 94.1\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m และ 75.3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m ตามลำดับ ดังที่แสดง เรายังใช้ความสนใจที่คำนึงถึงคีย์ที่เสนอในตารางที่ 2 ซึ่งจะกล่าวถึงใน Sec 3.6 เพื่อดำเนินการโมดูล KDA ให้ความสนใจและอัปเดตโทเค็น อย่างเป็นทางการ; กระบวนการอัปเดตสามารถอธิบายได้ว่าเป็น 3.3. การอัปเดตแบบแทรกสลับ จากแรงจูงใจของเรา คอขวดต่อตัวเข้ารหัสที่มีประสิทธิภาพนั้นเป็นคุณสมบัติระดับต่ำมากเกินไป ซึ่งส่วนใหญ่ไม่ได้ให้ข้อมูล แต่มีรายละเอียดในท้องถิ่นสำหรับวัตถุขนาดเล็ก นอกจากนี้; คุณลักษณะหลายระดับ S มีโครงสร้างโดยธรรมชาติ โดยที่คุณลักษณะระดับสูงจำนวนเล็กน้อยเข้ารหัสความหมายที่หลากหลาย แต่ไม่มีคุณลักษณะเฉพาะที่สำคัญสำหรับการจัดลำดับความสำคัญ ดังนั้นวัตถุขนาดเล็กบางรายการ เราเสนอคุณสมบัติต่างๆ ในระดับที่แตกต่างกันในลักษณะที่มีการสลับกัน t0 ความแม่นยำและการแลกเปลี่ยนประสิทธิภาพ: เราบรรลุการแบ่ง S ออกเป็นคุณสมบัติระดับต่ำ FL € RNLxd, odel และคุณสมบัติระดับสูง Xdmodel Fi โดยที่ dmodel คือขนาดของช่องสัญญาณ RNn € และ NH และ NL เป็นหมายเลขโทเค็นที่สอดคล้องกัน 33\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mNL) FH สามารถมี O 6\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m สามตัวแรกได้ (NH สองสเกลในการตั้งค่าที่แตกต่างกัน เพื่อความชัดเจน เราตั้งค่า FH เป็น S1,82, S3 และ FL เป็น S4 ตามค่าเริ่มต้น : FH ถือเป็นคุณสมบัติหลักและได้รับการอัปเดตบ่อยกว่า ในขณะที่ FL ได้รับการอัปเดตน้อยกว่า: เนื่องจากความสนใจที่เปลี่ยนรูปได้มีความซับซ้อนเชิงเส้นพร้อมการสืบค้นคุณลักษณะ คุณลักษณะระดับสูงที่อัปเดตบ่อยครั้งจำนวนเล็กน้อยจะช่วยลดต้นทุนการคำนวณได้มาก: ดังที่แสดง ในรูปที่ 2 เราสแต็คบล็อก effi จะอัปเดตบล็อกตัวเข้ารหัส cient สำหรับ B ครั้ง โดยที่แต่ละอัปเดตฟีเจอร์ระดับสูงระดับต่ำสำหรับ A ครั้ง แต่จะฟีเจอร์เพียงครั้งเดียวที่ส่วนท้ายของบล็อก ด้วยวิธีนี้ เราสามารถเต็มสเกลได้ ฟีเจอร์ปิรามิดที่มีต้นทุนการบำรุงรักษาที่ต่ำกว่ามาก: ด้วยการอัปเดตแบบแทรกนี้ เราได้ออกแบบกลไกการอัปเดตที่มีประสิทธิภาพสองประการสำหรับ FL และ FH - โดยที่ Concat คือการเชื่อมโยงคุณสมบัติระดับต่ำและระดับสูงเข้ากับคุณสมบัติเต็มรูปแบบ แบบสอบถาม Q คือคุณสมบัติระดับสูงเริ่มต้น K และ V เป็นคุณสมบัติเริ่มต้นจากทุกระดับ_ อัปเดต และ FH เป็นโทเค็นระดับสูง และ FH คือ คุณสมบัติระดับสูง การอัปเดตฟีเจอร์ระดับสูงของ Jayer จะถูกซ้อนกันหลายเลเยอร์ Atimes) เพื่อการแยกฟีเจอร์ซ้ำ หมายเหตุ (เช่น ple FH จะอัปเดต Q และสอดคล้องกับฟีเจอร์ระดับสูงที่ได้รับการอัปเดตในพีระมิดฟีเจอร์หลายสเกลซ้ำแล้วซ้ำอีก ซึ่งทำให้ฟีเจอร์อัปเดตใน K และในส่วนที่น่าสนใจคือเลเยอร์การอัปเดตฟีเจอร์ระดับสูงนี้: ถัดไป โมดูลคล้ายกับตัวถอดรหัส Transformer โดยที่เราโทเค็นระดับสูงเพื่อสอบถาม fea ของพวกเขาจำนวนเล็กน้อยของการใช้งานจำนวนมากคล้ายกับการดูแลตนเองและสอบถามคุณสมบัติระดับต่ำที่คล้ายกัน t0 ความสนใจข้าม รูปที่ 4 การเปรียบเทียบกลยุทธ์ตัวเข้ารหัสที่มีประสิทธิภาพก่อนหน้านี้ใน (a) DETR ที่เปลี่ยนรูปได้ [37], (b) DETR แบบกระจาย [25] และ (c) การใช้เครื่องชั่งระดับสูงสามตัวแรกเพียงเล็กน้อยเท่านั้น (d) ตัวเข้ารหัสที่มีประสิทธิภาพเบื้องต้นเพื่ออัปเดตคุณสมบัติระดับสูงเท่านั้น_ เรายังนำเสนอผลลัพธ์ของ (c) และ (d) ในตารางที่ 5_ สามารถกำหนดความสนใจได้เป็น รูปที่ 3 ภาพประกอบของ Key-aware Deformable At layer ที่เสนอ: tention KDA 3.5. ฟิวชั่นข้ามสเกลคุณสมบัติระดับต่ำที่มีประสิทธิภาพ โดยที่เส้นโครงเป็นเมทริกซ์พารามิเตอร์ WA WP Rdmodel X Nu และ dmodel Rdmodel WV p เป็นจุดอ้างอิงของคุณลักษณะเคียวรี และ Ap;p € R(Nn+NL)xNx2 S คือปิรามิดคุณลักษณะหลายสเกล ด้วยการสุ่มตัวอย่าง off- จะคำนวณคุณสมบัติด้วยฟังก์ชัน Samp( S,p + Ap; ตั้งค่า Ap) ในตำแหน่งตัวอย่าง (p + Ap) ของพีระมิดคุณลักษณะ โปรดทราบว่าไม่มีคีย์ใดเข้าร่วม S ด้วยการแก้ไขแบบไบลิเนียร์: ในเลเยอร์ความสนใจที่เปลี่ยนรูปได้ดั้งเดิม ; บ่งชี้ว่าแบบสอบถามสามารถตัดสินใจความสำคัญของค่าตัวอย่างแต่ละค่าด้วยคุณลักษณะเท่านั้นโดยไม่ต้องเปรียบเทียบกับคีย์ เนื่องจากคุณสมบัติหลายสเกลทั้งหมดจะเป็นตำแหน่งตัวอย่างการสืบค้นและน้ำหนักความสนใจ โมเดลดั้งเดิมจึงสามารถเรียนรู้วิธีประเมินความสำคัญของตำแหน่งตัวอย่างแต่ละตำแหน่งได้อย่างรวดเร็วตามการสืบค้น อย่างไรก็ตาม การอัปเดตแบบแทรกในตัวเข้ารหัสของเราทำให้ยาก สำหรับการสืบค้นเพื่อตัดสินใจทั้งน้ำหนักความสนใจและตำแหน่งการสุ่มตัวอย่างในแผนที่คุณลักษณะแบบอะซิงโครนัสอื่น ๆ ดังแสดงในรูปที่ 5 ดังที่แสดงในตารางที่ 2 คุณลักษณะระดับต่ำมีโทเค็นมากเกินไป ซึ่งเป็นปัจจัยสำคัญสำหรับการคำนวณที่ไม่มีประสิทธิภาพ ดังนั้น ตัวเข้ารหัสที่มีประสิทธิภาพจะอัปเดตคุณลักษณะระดับต่ำเหล่านี้ที่ความถี่ต่ำกว่าหลังจากลำดับของระดับสูง การผสมผสานคุณสมบัติ โดยเฉพาะอย่างยิ่ง เราใช้การสืบค้นระดับต่ำเริ่มต้นเพื่อโต้ตอบกับคุณสมบัติระดับสูงที่อัปเดตเป็นโทเค็นการอัปเดต เช่นเดียวกับคุณสมบัติระดับต่ำดั้งเดิมที่คล้ายกับการอัปเดตคุณสมบัติระดับสูง การเป็นตัวแทนเราใช้การโต้ตอบกับ KDA ชั้นความสนใจ: อย่างเป็นทางการเรามี มาจากคุณลักษณะระดับต่ำดั้งเดิม FH และ FL ซึ่งเป็นคุณลักษณะระดับสูงและระดับต่ำที่ได้รับการปรับปรุงตามข้อกำหนด FL ในที่สุดชั้น KDA; อย่างเป็นรูปธรรม: หลังจากที่เราได้รับแล้ว เราจะสร้างคุณลักษณะหลายระดับเอาต์พุต S\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m โดยการเชื่อมโยงคุณลักษณะระดับ Iow และระดับสูงที่ได้รับการปรับปรุงเข้าด้วยกัน เพื่อลดต้นทุนในการคำนวณต่อไป เราใช้เครือข่ายฟีดฟอร์เวิร์ดน้ำหนักเบาซึ่งมีขนาดมิติที่ซ่อนอยู่ F ของขนาดดั้งเดิม เป็นแบบของเราคือ 8 เพื่อให้เหมาะสมกับการออกแบบตัวเข้ารหัสที่มีประสิทธิภาพมากขึ้น เราขอเสนอแนวทาง KDA) เพื่อเน้นย้ำความสนใจที่เปลี่ยนรูปได้ของ sam key-aware โดยใช้คีย์ทั้งสองในแบบสอบถาม ดังแสดงในรูปที่: และค่าสำหรับคีย์และค่าตัวอย่าง ร่วมกับแบบสอบถาม 3_ จากนั้นจะดำเนินการสนใจดอทโปรดัคมาตราส่วนมาตรฐาน_ อย่างเป็นทางการแล้ว เรามี 3.6. ความสนใจที่เปลี่ยนรูปได้แบบรับรู้คีย์ ชั้น; ความสนใจที่เปลี่ยนรูปได้ทั่วไป การสืบค้น In จะถูกแบ่งออกเป็นหัว M และแต่ละหัวจะสุ่มตัวอย่างจุด K จากฟีเจอร์ L แต่ละรายการจะปรับขนาดเป็นค่า V ดังนั้น จำนวนค่าทั้งหมดที่สุ่มตัวอย่างสำหรับการสืบค้นคือ Nv M X L x K การชดเชยการสุ่มตัวอย่างจะชดเชย Ap และน้ำหนักความสนใจที่สอดคล้องกันนั้นเป็นแบบสอบถามที่คาดการณ์โดยตรงโดยใช้จากการฉายภาพเชิงเส้นสองรายการที่แสดงเป็น WP และ WA Deformable โดยที่ dk คือมิติสำคัญของส่วนหัว ความซับซ้อนในการคำนวณของ KDA นั้นเหมือนกับความสนใจที่เปลี่ยนรูปได้ดั้งเดิม เนื่องจากเราสุ่มตัวอย่างค่าจำนวนเท่ากันสำหรับการสืบค้นแต่ละครั้ง: ด้วยวิธีนี้ KDA จึงสามารถคาดการณ์น้ำหนักความสนใจที่เชื่อถือได้มากขึ้น เมื่ออัปเดตคุณสมบัติจากระดับที่ต่างกัน ผลลัพธ์สำหรับโมเดลที่ใช้ DETR ระดับเดี่ยวซึ่งใช้แผนผังคุณลักษณะความละเอียดที่ใหญ่กว่าพร้อมการขยาย (DCS) และโมเดลแบบ Deformable Table 3_ โมเดลที่ใช้ DETR เพื่อปรับปรุงประสิทธิภาพ ทุกรุ่นใช้ ResNet-50 Sparse DETR ขึ้นอยู่กับพื้นฐาน DETR ที่เปลี่ยนรูปได้ที่ได้รับการปรับปรุง ซึ่งรวมส่วนประกอบจาก Efficient DETR [33] \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrho\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m คืออัตราส่วนการรักษาของโทเค็นตัวเข้ารหัสใน Sparse DETR ที่ใช้ค่าในวงเล็บระบุเปอร์เซ็นต์ของโทเค็นระดับสูงของเราเมื่อเปรียบเทียบกับคุณสมบัติดั้งเดิมซึ่งเป็นผลมาจากรหัสฐาน DETR ที่ปรับรูปแบบได้อย่างเป็นทางการของเรา ความหมายของรุ่นต่างๆ มีอธิบายไว้ในมาตรา 2 4.1_ 3.7. การสนทนากับ Sparse DETR และตัวแปรที่มีประสิทธิภาพอื่นๆ ผลลัพธ์ความแม่นยำเฉลี่ยเฉลี่ย (AP) มาตรฐานภายใต้เกณฑ์ IoU และระดับวัตถุที่แตกต่างกัน เราประเมินประสิทธิภาพของรายละเอียดการใช้งาน: Lite DETR บนโมเดลที่ใช้ DETR หลายรุ่น รวมถึง Deformable DETR [37], H-DETR 11] และ DINO [36] โมเดลเหล่านี้มีโครงสร้างคล้ายกันซึ่งประกอบด้วยตัวเข้ารหัส Transformer หลายชั้นด้านหลัง และกระดูกหลายชั้น ดังนั้น เพียงแทนที่ตัวถอดรหัส Transformer ที่เราเข้ารหัสด้วยโมดูลที่มีประสิทธิภาพที่เราเสนอ ส่วนประกอบอื่นๆ ของรุ่นจะยังคงเหมือนเดิมกับรุ่นดั้งเดิม ในความสนใจของ KDA ของเรา สำหรับการเปรียบเทียบที่เป็นธรรม เราปฏิบัติตามการตั้งค่าที่เปลี่ยนรูปได้ t0 ใช้ M-8 และ K=4 อื่นๆ ตามมาด้วย เราใช้แบ็คโบน ResNet-50 [10] สองตัว และรุ่นดั้งเดิม Swin-T [20] ได้รับการฝึกอบรมล่วงหน้าเกี่ยวกับชุดข้อมูล ImageNet-IK [7] ในการทดลอง ของเรา อีกวิธีที่มีประสิทธิภาพคือ t0 ลดโทเค็นตัวเข้ารหัสโดยเลือกโทเค็นเด่นในฟีเจอร์หลายขนาด เช่น Sparse อย่างไรก็ตาม มีข้อเสียสามประการสำหรับ DETR นี้ [25]: ประเภทของแนวทาง: ประการแรก เป็นการยากที่จะสรุปในโมเดลที่ใช้ DETR อื่นๆ เนื่องจากจะทำให้คุณลักษณะที่มีโครงสร้างหรือ ganization เสียหาย ประการที่สอง โทเค็นที่เลือกผ่านเครือข่ายการให้คะแนนที่เหมาะสมที่สุดเนื่องจากการกำกับดูแลที่จำกัดและโดยปริยายอาจไม่ใช่ ประการที่สาม โดยจะแนะนำส่วนประกอบอื่นๆ เช่น การสูญเสียการตรวจจับตัวเข้ารหัส aux iliary หลายตัว เพื่อปรับปรุงตัวเข้ารหัสแบบกระจัดกระจาย เนื่องจากตัวเข้ารหัสมีหน้าที่รับผิดชอบในการแสดงคุณลักษณะ เพิ่มการควบคุมการตรวจจับทำให้ยากต่อการสกัด นำไปใช้กับรุ่นที่มีอยู่\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m นอกจากนี้; เราแสดงตัวเข้ารหัสที่มีประสิทธิภาพก่อนหน้านี้และการออกแบบที่มีประสิทธิภาพเบื้องต้นในรูปที่ 4 เพื่อการเปรียบเทียบที่ชัดเจน ตัวแปรตัวเข้ารหัสที่มีประสิทธิภาพ: ในบล็อกตัวเข้ารหัสที่มีประสิทธิภาพที่เราเสนอ ไฮเปอร์พารามิเตอร์สามตัวควบคุมต้นทุนการคำนวณ รวมถึงจำนวนฟีเจอร์สเกลระดับสูง H ที่ใช้ใน FH จำนวนบล็อกตัวเข้ารหัสที่มีประสิทธิภาพ Bและจำนวนของฟีเจอร์ข้ามสเกลระดับสูงซ้ำๆ ดังนั้นเราจึงใช้ HL-(A+ 1) X fusion A_ B เพื่อแสดงตัวแปรแต่ละรุ่นของ Lite DETR ของเรา โดยที่ L คือจำนวนของสเกลฟีเจอร์ระดับต่ำ และ +l หมายถึงแต่ละตัวแปรของ Lite DETR ของเรา การรวมฟีเจอร์ข้ามสเกลระดับต่ำที่มีประสิทธิภาพเริ่มต้นที่ส่วนท้ายของแต่ละบล็อก ตัวอย่างเช่น Lite-DINO H3LI-(3+1)x2 ระบุว่าเราใช้ DINO เพื่อใช้ฟีเจอร์สเกลระดับสูง (H3LI) สามอันและมีประสิทธิภาพสองอัน บล็อกตัวเข้ารหัสที่มีฟิวชั่นระดับสูงสามตัว ((3+1)x2) 4. การทดลอง 4.1. ติดตั้ง เราแสดงให้เห็นถึงความสามารถในการวางลักษณะทั่วไปของตัวเข้ารหัสที่มีประสิทธิภาพ prO ของเราในซีรีส์ของแบบจำลองที่ใช้ DETR_ เรายังประเมินประสิทธิผลของแต่ละส่วนประกอบด้วยการระเหย_ เราศึกษา Lite DETR บนชุดข้อมูล MS ที่ท้าทาย: ชุดข้อมูลการตรวจจับ COCO 2017 [17] ตามหลักปฏิบัติทั่วไป เราฝึกอบรมการแยกการฝึกอบรมและรายงานประสิทธิภาพการตรวจจับบน Val2017 แยกการตรวจสอบความถูกต้อง เรารายงาน 4.2. การปรับปรุงประสิทธิภาพของ DETR ที่เปลี่ยนรูปได้ ตัวเข้ารหัส lite ที่เสนอเพื่อแทนที่ ในตารางที่ 3 เราใช้ตัวเข้ารหัสที่เปลี่ยนรูปได้ใน Deformable DETR และสร้าง Lite ในการทดลองของเรากับ DINO [36] ด้วยแกนหลัก ResNet-50 การเพิ่มการสูญเสียการตรวจจับตัวเข้ารหัสเพียงอย่างเดียวจะทำให้ AP ลดลง 1.4 ผลลัพธ์สำหรับโมเดลที่ใช้ DETR ที่เปลี่ยนรูปได้ เพื่อปรับปรุงประสิทธิภาพด้วยการออกแบบตัวเข้ารหัสแสงของเรา นอกจากนี้เรายังเปรียบเทียบกับโมเดลที่ใช้ CNN ที่มีประสิทธิภาพ Table 4 และโมเดลที่ใช้ DETR ที่มีประสิทธิภาพอื่นๆ_ ทุกรุ่นยกเว้นซีรีส์ EfficientDet และ YOLO อิงตาม ResNet-50 และ Swin-T ที่ได้รับการฝึกอบรมล่วงหน้าบน ImageNet-IK เปอร์เซ็นต์ในชื่อโมเดลบ่งบอกถึงเปอร์เซ็นต์ของโทเค็นที่ถูกบีบอัดของเรา ความหมายของตัวแปรโมเดลต่างๆ ได้อธิบายไว้ในมาตรา 2 4.1. เมื่อเทียบกับคุณสมบัติเดิม นอกจากนี้ หลังจากเสียบปลั๊กตัวเข้ารหัสที่มีประสิทธิภาพของเราแล้ว GFLOP ของตัวเข้ารหัสสามารถลดลงได้ 78\u001b[39m\u001b[38;5;132;01m% 62%\u001b[39;00m\u001b[38;5;124m เมื่อเทียบกับตัวดั้งเดิมในขณะที่ยังคงรักษาประสิทธิภาพดั้งเดิมไว้ 99\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m โดยเฉพาะอย่างยิ่งจาก Swin-Tiny Lite-DINO ของเราได้รับ 53.9 AP ด้วย 159 GFLOP เท่านั้น ซึ่งมีประสิทธิภาพเหนือกว่ารุ่น YOLO ซีรีส์ด้วย 12,30] ภายใต้ GFLOP เดียวกัน เราบรรลุประสิทธิภาพที่เทียบเท่ากับ DETR ที่เปลี่ยนรูปได้ DETR ที่เปลี่ยนรูปได้โดยมีประมาณ 40\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m ของ GFLOP ของตัวเข้ารหัสดั้งเดิม นอกจากนี้เรายังสามารถสังเกตได้ว่าโมเดลที่ใช้ DETR สเกลเดียวของฟีเจอร์แมปขนาดใหญ่นั้นถูกคำนวณด้วยโมเดลหลายสเกล t0 ที่ไม่มีประสิทธิภาพและด้อยกว่า ในการฟิวชั่นข้ามสเกลระดับสูงแบบวนซ้ำ เราสามารถนำแผนที่ระดับสูงมาใช้อย่างมีประสิทธิภาพโดยมีเพียงสองหรือสามโมเดลเท่านั้น แผนที่ระดับสูงซึ่งสามารถลดการสืบค้นในเลเยอร์ตัวเข้ารหัสลงเหลือ 5\u001b[39m\u001b[38;5;132;01m% 25%\u001b[39;00m\u001b[38;5;124m ของโทเค็นดั้งเดิม เมื่อเปรียบเทียบกับตัวแปรที่มีประสิทธิภาพอื่น ๆ ทำให้เราบรรลุประสิทธิภาพที่ดีขึ้นภายใต้ DETR ที่เปลี่ยนรูปได้ ต้นทุนการคำนวณ: ตัวอย่างเช่น เรามีประสิทธิภาพเหนือกว่า Sparse DETR เดียวกัน -rho-0.3 คูณ 0.7 AP โดยมี GFLOP น้อยลง นอกจากนี้ Sparse DETR ยังอิงตามพื้นฐานที่ได้รับการปรับปรุงซึ่งรวม DETR ที่มีประสิทธิภาพและ DETR ที่เปลี่ยนรูปได้ ตรงกันข้าม; DETR ที่เปลี่ยนรูปได้เล็กน้อยของเรานั้นเรียบง่ายและมีประสิทธิภาพ 4.4. การแสดงภาพ KDA นอกจากนี้เรายังจัดให้มีการแสดงภาพความสนใจของ KDA ของเราด้วย ในตัวเข้ารหัสแบบอินเทอร์ลีฟของเราในข้อ 5 เปรียบเทียบกับดีคีย์ ความสนใจที่จัดรูปแบบได้ เนื่องจากเราแนะนำความสนใจของ KDA ที่จะทำนายน้ำหนักที่เชื่อถือได้มากขึ้น โดยเฉพาะอย่างยิ่งในกระป๋องระดับต่ำ รูป: ตัวอย่างเช่น ใน S(a) แผนที่คุณลักษณะตำแหน่งที่สุ่มตัวอย่าง_ ของความสนใจที่เปลี่ยนรูปได้ใน S4 (แสดงด้วยรูปสามเหลี่ยม) รูปที่: มีความน่าเชื่อถือน้อยกว่าเมื่อเทียบกับ KDA ใน 5(b) และ (c) เราสังเกตเห็นว่าเป็นเรื่องยากสำหรับความสนใจที่เปลี่ยนรูปได้เพื่อเน้นบริเวณที่มีความหมายบนแผนที่มาตราส่วนที่ใหญ่ที่สุด S4 ใน KDA ของเราช่วยลดการทำงานของตัวเข้ารหัส phe-interleaved นี้ได้อย่างมีประสิทธิภาพ: นำ nomenon ซึ่งช่วยดึงคุณลักษณะในท้องถิ่นที่ดีขึ้น ประสิทธิภาพของวัตถุขนาดเล็กกลับ: การปรับปรุงประสิทธิภาพ DETR- 4.3 อื่น ๆ ตามโมเดลพื้นฐาน เมื่อเปรียบเทียบกับตัวแปรที่มีประสิทธิภาพอื่นๆ กรอบงานการตรวจจับและเครื่องหมายเฉพาะที่มีประสิทธิภาพของเราไม่ได้จำกัดอยู่ที่ สามารถเสียบเข้ากับรุ่นที่ใช้ DETR อื่นๆ ได้อย่างง่ายดาย เรา 11] เป็นตัวอย่างเพื่อแสดงประสิทธิภาพของ DINO [36] และ H-DETR ของตัวเข้ารหัสที่มีประสิทธิภาพของเรา: ผลลัพธ์แสดงในตารางที่ 4 เมื่อเปรียบเทียบกับโมเดลที่คล้ายกับ DETR ที่มีประสิทธิภาพอื่นๆ ที่เสนอเมื่อเร็วๆ นี้ [8,35] แบบจำลองของเราประสบความสำเร็จ ประสิทธิภาพที่ดีขึ้นอย่างมากด้วยต้นทุนการคำนวณที่เทียบเคียงได้ ใน 4.5. การศึกษาการระเหย ประสิทธิผลของส่วนประกอบที่เสนอแต่ละรายการ: ในตาราง เราแสดงประสิทธิภาพของส่วนประกอบที่เราเสนอ 5 เราเลือกมาตราส่วน DINO-3 และมาตราส่วน DINO-2 เป็นพื้นฐาน ซึ่งใช้เฉพาะคุณลักษณะระดับสูงสามและสองรายการแรกเท่านั้น การใช้การแสดงความสนใจของ KDA ในตัวเข้ารหัสแบบอินเทอร์ลีฟของเรา: แถวที่หนึ่งและที่สองคือแผนที่ความสนใจของรูปที่ 5_ ที่เปลี่ยนรูปได้และความสนใจของ KDA ของเรา (a) เราใช้จุดศูนย์กลางของวัตถุจาก Sl (ทำเครื่องหมายด้วยสีเขียวเป็นการสืบค้น และวาดการสุ่มตัวอย่าง 100 อันดับแรกตามน้ำหนักความสนใจ ตำแหน่งการสุ่มตัวอย่างบน S4 จะถูกทำเครื่องหมายด้วยรูปทรงสามเหลี่ยม (b)&(c) ตำแหน่งในทั้งสี่ระดับ เราแสดงตำแหน่งการสุ่มตัวอย่าง 200 อันดับแรกในระดับ S3 (b) และ S4 (c) สำหรับโทเค็นการสืบค้นทั้งหมด_ การแสดงภาพแสดงให้เห็นว่า KDA สามารถผลิตได้มากขึ้น เพื่อความชัดเจน เราจะดึงตำแหน่งของน้ำหนักความสนใจเพียง 200 ตำแหน่งจากการสุ่มตัวอย่างทั้งหมด น้ำหนักความสนใจที่เชื่อถือได้สูงสุดบนแผนที่ที่มีความละเอียดสูง_ การแสดงภาพเพิ่มเติมจะแสดงในตำแหน่งภาคผนวก_ (Nq X M x K; Nq คือจำนวนโทเค็นการสืบค้นแบบหลายสเกลทั้งหมด) บน S3 และบน S4_ ตัวเลือกที่เหมาะสมที่สุดในการสแต็กแต่ละ mod ในตารางที่ 6 เราสำรวจ ule ในบล็อกที่มีประสิทธิภาพที่เราเสนอ: อิงตาม Deformable ResNet-50 backbone, DETR [37] โดยเราเปลี่ยนแปลง ar guments สามตัวที่มีอิทธิพลต่อความซับซ้อนในการคำนวณและประสิทธิภาพการตรวจจับ รวมถึงจำนวน ของสเกลระดับสูง H ใช้เป็นคุณสมบัติระดับสูง บล็อกตัวเข้ารหัสที่มีประสิทธิภาพ B และฟิวชั่นข้ามสเกลคุณสมบัติระดับสูงซ้ำ ประสิทธิภาพ A จะดีขึ้นเมื่อเราใช้สเกลคุณสมบัติระดับสูงมากขึ้นและบล็อกตัวเข้ารหัสมากขึ้นเพื่ออัปเดตระดับต่ำ คุณสมบัติระดับอย่างไรก็ตาม; การเพิ่มหมายเลขโมดูลเพิ่มเติมเป็น (2 + 1) X 4 จะไม่ปรับปรุงประสิทธิภาพ_ ตารางที่ 5_ ประสิทธิผลของแต่ละส่วนประกอบใน COCO val2017 ที่ได้รับการฝึกอบรม 36 ยุค ผลลัพธ์จะขึ้นอยู่กับ DINO พร้อมด้วยแกนหลัก ResNet-S0 ที่ได้รับการฝึกอบรม 36 ยุค HL หมายถึง ฟิวชั่นข้ามสเกลคุณลักษณะระดับสูงซ้ำๆ LL หมายถึง ฟิวชั่นข้ามสเกลคุณลักษณะระดับต่ำที่มีประสิทธิภาพ และ KDA คือการรับรู้ที่สำคัญที่เปลี่ยนรูปได้ 5. สรุป ในบทความนี้ เราได้วิเคราะห์ว่าคุณสมบัติหลายสเกลที่มีคุณสมบัติระดับต่ำมากเกินไปในตัวเข้ารหัส Transformer เป็นสาเหตุหลักของการคำนวณที่ไม่มีประสิทธิภาพในแบบจำลองที่ใช้ DETR เราได้นำเสนอ Lite DETR พร้อมบล็อกตัวเข้ารหัสที่มีประสิทธิภาพ ซึ่งแยกโทเค็นตัวเข้ารหัสออกเป็นคุณสมบัติระดับสูงและระดับต่ำ คุณสมบัติเหล่านี้จะได้รับการอัปเดตในความถี่ที่แตกต่างกันด้วยการผสมผสานข้ามสเกลเพื่อให้ได้ความแม่นยำและการแลกเปลี่ยนอย่างมีประสิทธิภาพ: เพื่อลดผลกระทบของคุณสมบัติอะซิงโครนัส เราได้เสนอคีย์เพิ่มเติม - รับรู้ถึงความสนใจที่เปลี่ยนรูปได้ ซึ่งนำประสิทธิภาพการตรวจจับของวัตถุขนาดเล็กกลับมาอย่างมีประสิทธิภาพ: เป็นผลให้; ตัวเข้ารหัสที่มีประสิทธิภาพที่เรานำเสนอสามารถลดต้นทุนการคำนวณได้ 60\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m ในขณะที่ยังคงประสิทธิภาพเดิมไว้ 99\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m นอกจากนี้ การออกแบบที่มีประสิทธิภาพนี้สามารถเสียบเข้ากับโมเดลการตรวจจับที่ใช้ DETR หลายๆ รุ่นได้อย่างง่ายดาย We Lite DETR สามารถสร้างพื้นฐานที่เรียบง่ายสำหรับการตรวจจับที่มีประสิทธิภาพในโมเดลวิดีโอที่ใช้ DETR เพื่อเป็นประโยชน์ต่อแอปพลิเคชันอื่นๆ ที่จำกัดทรัพยากร ตารางที่ 6 การศึกษาการระเหยเกี่ยวกับการซ้อนจำนวนที่แตกต่างกันของแต่ละโมดูลในบล็อกตัวเข้ารหัสที่มีประสิทธิภาพของเรา: โมเดลทั้งหมดสร้างขึ้นบน DETR-ResNet50 ที่เปลี่ยนรูปได้ และได้รับการฝึกอบรมมาเป็นเวลา 50 epochs_ แผนที่ ผลลัพธ์บ่งชี้ว่าส่วนประกอบที่เรานำเสนอแต่ละรายการต้องใช้ต้นทุนในการคำนวณ ในขณะเดียวกันก็ปรับปรุงประสิทธิภาพของโมเดลเพียงเล็กน้อยด้วยอัตรากำไรขั้นต้นที่เหมาะสม KDA ช่วยปรับปรุงประสิทธิภาพของ DINO เป็นหลัก โดยเฉพาะอย่างยิ่ง องค์ประกอบเหล่านี้นำประสิทธิภาพของวัตถุขนาดเล็กกลับมาอย่างมีประสิทธิภาพ ตัวอย่างเช่น AP ของมาตราส่วน DINO-3 ที่มีประสิทธิภาพของเรานั้นเทียบได้กับรุ่น DINO-4scale ดั้งเดิม ข้อจำกัด: ในบทความนี้เรามุ่งเน้นที่การลดความซับซ้อนในการคำนวณเป็นหลัก และไม่ปรับการใช้งานรันไทม์ของแบบจำลองที่ใช้ DETR ให้เหมาะสม เราปล่อยให้ t0 นี้ทำงานในอนาคตของเรา: อ้างอิง ตอนนี้ข้อมูลสิ้นสุดลงแล้ว แนวทางที่เป็นไปได้ในการปรับปรุงประสิทธิภาพและประสิทธิผลของ Lite DETR ต่อไปมีอะไรบ้าง\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m generated_textOPT \u001b[38;5;241m=\u001b[39m generate_OPT(instruction, \u001b[38;5;28minput\u001b[39m)\n",
      "Cell \u001b[0;32mIn[78], line 24\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(instruction, input)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16):\n\u001b[1;32m     23\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# temperature=0.1,\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m                             \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     final_outputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     35\u001b[0m     final_outputs \u001b[38;5;241m=\u001b[39m cut_off_text(final_outputs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</s>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1606\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1590\u001b[0m         input_ids,\n\u001b[1;32m   1591\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1603\u001b[0m     )\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:2454\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2454\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2457\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2462\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:1038\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1035\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:875\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    872\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, seq_length)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 875\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# embed positions\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"ด้านล่างเป็นข้อมูล จำข้อมูลและตอบคำถามของฉันหลังข้อมูล ข้อมูลเริ่มต้นขึ้น Abstract DETR รุ่น DEtection TRansformer ล่าสุดได้รับประสิทธิภาพที่โดดเด่น ความสำเร็จไม่สามารถเกิดขึ้นได้หากปราศจากการนำฟีเจอร์ฟิวชั่นหลายขนาดในตัวเข้ารหัสกลับมาใช้ใหม่: อย่างไรก็ตาม; โทเค็นที่เพิ่มขึ้นมากเกินไปในฟีเจอร์หลายสเกล โดยเฉพาะฟีเจอร์ระดับต่ำประมาณ 759 รายการนั้นไม่มีประสิทธิภาพในการคำนวณ ซึ่งค่อนข้างเป็นอุปสรรคต่อการใช้งานจริงของแบบจำลอง DETR ในบทความนี้ เรานำเสนอ Lite DETR ซึ่งเป็นเฟรมเวิร์กการตรวจจับวัตถุแบบ end-to-end ที่เรียบง่ายแต่ทรงประสิทธิภาพ ซึ่งสามารถลด GFLOP ของส่วนหัวการตรวจจับได้อย่างมีประสิทธิภาพถึง 60% ในขณะที่ยังคงรักษาประสิทธิภาพดั้งเดิมไว้ 99% โดยเฉพาะ; เราออกแบบบล็อกตัวเข้ารหัสที่มีประสิทธิภาพเพื่ออัปเดตคุณสมบัติระดับสูง (สอดคล้องกับแผนที่คุณสมบัติความละเอียดขนาดเล็ก) และคุณสมบัติระดับต่ำ (สอดคล้องกับแผนที่คุณสมบัติความละเอียดสูงในลักษณะแทรกสลับ นอกจากนี้ เพื่อหลอมรวมคุณสมบัติข้ามสเกลได้ดีขึ้น เราพัฒนาความสนใจที่เปลี่ยนรูปได้โดยการรับรู้คีย์เพื่อคาดการณ์น้ำหนักความสนใจที่เชื่อถือได้มากขึ้น การทดลองที่ครอบคลุมจะตรวจสอบประสิทธิภาพและประสิทธิภาพของ Lite DETR ที่เสนอ และกลยุทธ์ตัวเข้ารหัสที่มีประสิทธิภาพสามารถสรุปได้ดีในโมเดลที่ใช้ DETR ที่มีอยู่: รหัสที่พร้อมใช้งานจะเป็น IDEA-Research /Lite ใน https / /github _ com DETR รูปที่ 1 แกนความแม่นยำเฉลี่ย) เทียบกับ GFLOP (แกน X) สำหรับการฝึกอบรมข้อมูลโมเดลการตรวจจับที่แตกต่างกันบน COCO โดยไม่ต้องเพิ่มเติม ทุกรุ่นยกเว้น EfficientDet [29] และ YOLO ซีรีส์ [12,30] ใช้ Tiny เป็นแบ็คโบน โดยเฉพาะเครื่องหมายสองตัว ResNet-50 และ Swin- Tiny; ตามลำดับ: ในบรรทัดเดียวกันให้ใช้ ResNet-50 และ Swin- In เครื่องหมายแยกใช้เฉพาะ ResNet-50_ แต่ละเส้นประเชื่อมต่อการเพิ่มตัวแปรอัลกอริทึมก่อนและหลังอัลกอริทึม ขนาดรุ่นที่ระบุไว้ของเราแตกต่างกันไปตั้งแต่ 32M ถึง 82M: เมื่อเร็วๆ นี้ DEtection TRansformer [1] DETR แนะนำ Transformers ในการตรวจจับวัตถุ และโมเดลที่คล้าย DETR ได้รับประสิทธิภาพที่คาดหวังในงานวิชันพื้นฐานหลายอย่าง เช่น การตรวจจับวัตถุ [13,36,37] การแบ่งส่วนอินสแตนซ์ [5,6,14] และก่อให้เกิดการประมาณค่า [26,28] 1. บทนำ ตามแนวคิด DETR [1] ประกอบด้วยสามส่วน: กระดูกสันหลัง ตัวเข้ารหัส Transformer; และงานวิจัยของ Transformer de Many ได้ปรับปรุง back coder: กระดูกและชิ้นส่วนตัวถอดรหัส ตัวอย่างเช่น กระดูกสันหลังใน DETR โดยปกติจะสืบทอดมาและได้รับประโยชน์อย่างมากจากแบบจำลองการจำแนกประเภทที่ผ่านการฝึกอบรมมาแล้ว 10, 20]: ส่วนตัวถอดรหัสใน DETR เป็นจุดสนใจในการวิจัยหลัก โดยมีงานวิจัยจำนวนมากที่พยายามแนะนำโครงสร้างที่เหมาะสมให้กับแบบสอบถาม DETR และฉันกำลังพิสูจน์อยู่ ประสิทธิภาพการฝึก 11,13,18,21,36,37]. โดยคอน การตรวจจับวัตถุมีจุดมุ่งหมายเพื่อตรวจจับวัตถุที่น่าสนใจในยุคของภาพโดยจำกัดกรอบขอบเขตของมันและคาดการณ์ ในทศวรรษที่ผ่านมา คะแนนการจำแนกประเภทที่เกี่ยวข้องกันมีความก้าวหน้าอย่างเห็นได้ชัดได้ถูกสร้างขึ้นโดยโมเดล de tection แบบคลาสสิกจำนวนมาก [23, 24] บนเครือข่ายแบบ convolutional Feng งานนี้เกิดขึ้นเมื่อ Li ฝึกงานที่ IDEA โทเค็นดั้งเดิมที่คำนวณได้จำนวนมากและบันทึกที่ส่วนท้ายของบล็อกตัวเข้ารหัส เราปล่อยให้ต้นทุนในระดับต่ำ: kens ค้นหาแผนที่คุณลักษณะทั้งหมดเพื่ออัปเดตการเป็นตัวแทน ดังนั้น จึงรักษาคุณลักษณะหลายขนาดไว้ ในคุณลักษณะระดับสูงและระดับต่ำที่สอดแทรกในลักษณะที่แตกต่างกัน เราอัปเดตความถี่เพื่อการคำนวณที่มีประสิทธิภาพ จริงอยู่ งานน้อยลงมากแล้ว t0 ปรับปรุงส่วนตัวเข้ารหัส: ตัวเข้ารหัสในวานิลลา DETR มีเลเยอร์ Transformer หกชั้น ตัวเข้ารหัสซ้อนกันที่ด้านบนของกระดูกสันหลังเพื่อปรับปรุง เมื่อเปรียบเทียบกับแบบจำลองการตรวจจับแบบคลาสสิก มันขาดคุณสมบัติหลายขนาด ซึ่ง มีความสำคัญอย่างมากต่อการตรวจจับวัตถุ โดยเฉพาะอย่างยิ่งสำหรับการตรวจจับวัตถุขนาดเล็ก [9,16,19,22,29] การใช้เลเยอร์ Transformer en coder บนคุณสมบัติหลายขนาดนั้นไม่สามารถใช้งานได้จริง เนื่องจากต้นทุนการคำนวณที่ห้ามปรามซึ่งเป็นกำลังสองของจำนวนโทเค็นคุณสมบัติ ตัวอย่างเช่น DETR ใช้แผนผังคุณสมบัติ C5 ซึ่งเป็น 1/32 ของความละเอียดภาพอินพุต เพื่อใช้ตัวเข้ารหัส Transformer: หากรวมคุณสมบัติ C3 (สเกล 1/8) ไว้ในคุณสมบัติหลายสเกล จำนวนโทเค็นจากสเกลนี้เพียงอย่างเดียวจะเป็น 16 เท่าของโทเค็นจากต้นทุนการคำนวณของการเอาใจใส่ตนเองใน แผนผังคุณลักษณะ C5 หม้อแปลงไฟฟ้าจะสูง 256 เท่า: นอกจากนี้; เพื่อปรับปรุงคุณลักษณะระดับต่ำที่ล่าช้า up-key-aware deformable Attention (KDA) เราเสนอแนวทางในการแทนที่เลเยอร์ความสนใจทั้งหมด เมื่อดำเนินการให้ความสนใจที่เปลี่ยนรูปได้สำหรับแต่ละแบบสอบถาม โดยจะสุ่มตัวอย่างทั้งคีย์และค่าจากตำแหน่งการสุ่มตัวอย่างเดียวกันในแผนผังคุณลักษณะ จากนั้น จะสามารถคำนวณน้ำหนักความสนใจที่เชื่อถือได้มากขึ้นโดยการเปรียบเทียบแบบสอบถามกับคีย์ตัวอย่าง: วิธีการดังกล่าวยังถือได้ว่าเป็นความสนใจหนาแน่นแบบกระจัดกระจายแบบขยายที่ปรับเปลี่ยนรูปแบบได้ ความสนใจ หรือ เราพบว่า KDA มีประสิทธิภาพมากในการนำประสิทธิภาพกลับคืนมาด้วยบล็อกตัวเข้ารหัสที่มีประสิทธิภาพที่เสนอ: กับเรา เพื่อแก้ไขปัญหานี้ DETR ที่เปลี่ยนรูปได้ [37] พัฒนาอัลกอริธึมความสนใจที่ปรับรูปได้เพื่อลดความซับซ้อนของความสนใจในการดำเนินการด้วยตนเองจากกำลังสองเป็นเชิงเส้นโดยการเปรียบเทียบโทเค็นการสืบค้นแต่ละรายการด้วยจำนวนจุดสุ่มตัวอย่างคงที่เท่านั้น จากการคำนวณการเอาใจใส่ตนเองที่มีประสิทธิภาพนี้ DETR ที่เปลี่ยนรูปได้แนะนำคุณสมบัติหลายสเกลให้กับ DETR_ และตัวเข้ารหัสที่เปลี่ยนรูปได้ถูกนำมาใช้กันอย่างแพร่หลายในรุ่นที่คล้าย DETR ต่อมา 11,13,18,36] สรุปการมีส่วนร่วมของเรามีดังนี้_ เราเสนอบล็อกตัวเข้ารหัสที่มีประสิทธิภาพเพื่ออัปเดตคุณสมบัติระดับสูงและระดับต่ำในลักษณะแทรกซึม ลดโทเค็นคุณลักษณะลงอย่างมากซึ่งสามารถตรวจจับได้อย่างมีประสิทธิภาพ ตัวเข้ารหัสนี้สามารถเสียบเข้ากับรุ่นที่ใช้ DETR ที่มีอยู่ได้อย่างง่ายดาย เพื่อปรับปรุงการอัปเดตคุณสมบัติที่ล่าช้า เราแนะนำความสนใจที่เปลี่ยนรูปได้โดยการรับรู้คีย์เพื่อการทำนายน้ำหนักความสนใจที่เชื่อถือได้มากขึ้น: การทดลองที่ครอบคลุมแสดงให้เห็นว่า Lite DETR สามารถลด GFLOP ของหัวตรวจจับได้ 60% และประสิทธิภาพการตรวจจับหลัก 99% โดยเฉพาะอย่างยิ่ง Lite- DINO-SwinT ของเรามี AP 53.9 พร้อมด้วย 159 GFLOP โทเค็นการสืบค้นจำนวนมากแนะนำอย่างไรก็ตาม; เนื่องจากเกิดจากคุณสมบัติหลายขนาด ตัวเข้ารหัสที่เปลี่ยนรูปได้จึงมีต้นทุนการคำนวณสูง เพื่อเผยให้เห็นว่าสิ่งนี้ยังคงประสบปัญหาจากการทดลองเชิงวิเคราะห์ตามที่แสดงปัญหา เราดำเนินการ 2 รายการโดยใช้โมเดล DINO [36] ที่ใช้ DETR ในตารางและวิเคราะห์คอขวดของประสิทธิภาพของคุณสมบัติหลายขนาด_ สามารถสังเกตผลลัพธ์ที่น่าสนใจบางประการได้ อันดับแรก; คุณลักษณะระดับต่ำ (แผนที่ความละเอียดสูง) คิดเป็นสัดส่วนมากกว่า 75% ของโทเค็นทั้งหมด ประการที่สอง การลดคุณสมบัติระดับต่ำลงโดยตรง (สเกล DINO-3) ส่วนใหญ่ส่งผลต่อประสิทธิภาพการตรวจจับสำหรับวัตถุขนาดเล็ก (AP_S) ลดลง 10% แต่ส่งผลกระทบเพียงเล็กน้อยกับวัตถุขนาดใหญ่ (AP_L) 2. งานที่เกี่ยวข้อง เบื้องต้น: DETR [1] ถือว่าการตรวจจับวัตถุเป็นปัญหาการทำนายโดยตรง และใช้การสูญเสียทั่วโลกกับการทำนายแรงชุดตามชุดผ่านการจับคู่แบบสองฝ่าย: Vanilla DETR [1] ใช้เฉพาะคุณสมบัติระดับเดียวจากขั้นตอนที่ 3 สุดท้ายของอิมเมจอินพุต ความละเอียด) เช่น ของแบ็คโบน Xfeat RNx D โดยที่ Dis คือมิติฟีเจอร์และ N คือจำนวนฟีเจอร์ที่ราบเรียบทั้งหมด คุณสมบัติเหล่านี้จะถูกประมวลผลโดยตัวเข้ารหัสที่มีเลเยอร์การเอาใจใส่ตนเองหนาแน่นสำหรับการหลอมรวมและการปรับปรุงคุณสมบัติ: การใช้ 16 ] ในตัวเข้ารหัสโมเดลที่ใช้ CNN นั้นคล้ายคลึงกับ FPN คุณสมบัติที่ได้รับการปรับปรุงเหล่านี้จะถูกสอบถามโดยตัวถอดรหัสเพื่อตรวจจับวัตถุโดยการทำนายคะแนนการจำแนกประเภทและกล่องขอบเขตแบบถดถอย โดยทั่วไป เนื่องจาก DETR ใช้เฉพาะคุณสมบัติระดับสูงที่มีความละเอียดต่ำ คุณสมบัติเหล่านี้จึงขาดรายละเอียดภายในเครื่องที่สมบูรณ์ซึ่งมีความสำคัญต่อการตรวจจับวัตถุขนาดเล็ก ด้วยแรงบันดาลใจจากข้อสังเกตข้างต้น เรากระตือรือร้นที่จะตอบคำถาม: เราจะใช้มาตราส่วนฟีเจอร์น้อยลงแต่ยังคงรักษารายละเอียดที่สำคัญในท้องถิ่นไว้ได้หรือไม่ เรานำเสนอเฟรม DETR ที่มีประสิทธิภาพ โดยใช้ประโยชน์จากคุณสมบัติหลายสเกลที่มีโครงสร้าง โดยเฉพาะอย่างยิ่ง เราออกแบบงานที่เรียบง่าย ชื่อ Lite DETR รวมถึงเลเยอร์การใส่ใจในตัวเองของบล็อกตัวเข้ารหัสที่เปลี่ยนรูปได้แต่มีประสิทธิภาพ เป็นแบบพลักแอนด์เพลย์ในรุ่นฐาน DETR หลายขนาดที่สามารถลด GFLOP ของตัวเข้ารหัสได้ 62% 78% และรักษาประสิทธิภาพการแข่งขัน บล็อกตัวเข้ารหัสแบ่งคุณสมบัติหลายสเกลออกเป็น C6,C5,C4 ระดับสูง) และคุณสมบัติระดับต่ำ (เช่น (เช่น คุณสมบัติ C3)_ คุณสมบัติระดับสูงและระดับต่ำจะได้รับการอัปเดตในลักษณะแทรกสลับ เพื่อปรับปรุงพีระมิดฟีเจอร์หลายขนาด นั่นคือในสองสามเลเยอร์แรก เราปล่อยให้ฟีเจอร์ระดับสูงค้นหาแผนผังฟีเจอร์ทั้งหมดและปรับปรุงการนำเสนอ แต่ยังคงรักษาโทเค็นระดับต่ำไว้: กลยุทธ์ดังกล่าวสามารถลดจำนวนได้อย่างมีประสิทธิภาพ ของโทเค็นการสืบค้นถึง 5% 25% ของ การปรับปรุงการออกแบบตัวถอดรหัสของ DETR: เมื่อเร็วๆ นี้ เครื่องตรวจจับที่ใช้ DETR มีความก้าวหน้าที่รวดเร็วกว่า 13,18,21,33, 36] เมื่อเปรียบเทียบกับเครื่องตรวจจับแบบคลาสสิก [2,24] ผลที่ตามมา; DINO [36] คว้าอันดับหนึ่งในการตรวจจับวัตถุ COCO 2017 สำหรับโมเดลที่คล้าย DETR ครั้งแรกที่งานส่วนใหญ่เน้น ตารางที่ 1 GFLOP ของ DINO ที่ใช้ ResNet-50 โดยมีฟีเจอร์สเกล 4 สเกลและฟีเจอร์สเกล 3 สเกล ตามลำดับ: เราใช้ ResNet-50 เป็นแกนหลักและประเมิน COCO val2017 ที่ได้รับการฝึก 12 ยุค 100% หมายความว่าเราใช้โทเค็นฟีเจอร์ทั้งหมด ในขณะที่ 25% หมายความว่าเราใช้ฟีเจอร์ระดับสูงสามฟีเจอร์ซึ่งคิดเป็น 25% ของโทเค็นทั้งหมด_ ปรับปรุงตัวถอดรหัส Transformer ใน DETR เพื่อประสิทธิภาพที่ดีขึ้นและความเร็วการบรรจบกันที่เร็วขึ้น โดยเฉพาะตำแหน่ง Meng และคณะ [21 เสนอให้แยกเนื้อหาและข้อมูลในตัวถอดรหัสเพื่อให้มีลำดับความสำคัญเชิงพื้นที่ที่ดีขึ้นในการแปลเป็นภาษาท้องถิ่น [18, 37] ออกแบบสูตรการสืบค้นตำแหน่งที่ดีกว่างานก่อนหน้านี้ รูปแบบการกำหนดป้ายกำกับแบบตัวต่อตัวยังถูกกล่าวถึงอย่างกว้างขวางในการมอบหมาย [4,11,13,36] ยิ่งไปกว่านั้น การออกแบบให้ดีขึ้นสำหรับบางรุ่น [33,36,37] การเริ่มต้นคิวรีตัวถอดรหัสที่ดีกว่าโดยใช้ Priors ที่หนาแน่นจากตัวเข้ารหัส: ตารางที่ 2 อัตราส่วนโทเค็นของแต่ละสเกลฟีเจอร์ในพีระมิดฟีเจอร์ 4 สเกล 3. วิธีการ 3.1. แรงจูงใจและการวิเคราะห์ ในส่วนนี้ ก่อนอื่นเราจะวิเคราะห์ว่าทำไมโมเดลที่น่าสนใจที่ใช้ DETR ที่มีอยู่จึงยังคงไม่มีประสิทธิภาพ จากนั้นจึงแสดงคุณลักษณะหลายสเกลบางอย่างที่มีความสำคัญอย่างยิ่งต่อการสังเกต โดยจะตรวจจับวัตถุที่มีสเกลที่หลากหลาย ประกอบด้วยคุณสมบัติหลายระดับตั้งแต่คุณสมบัติระดับสูง (ความละเอียดต่ำ) ไปจนถึงคุณสมบัติระดับต่ำ (ความละเอียดสูง) โทเค็นระดับล่างแต่ละอันที่มากกว่าแผนผังคุณสมบัติก่อนหน้านี้มีระดับ ture 4 เท่า_ จากตารางที่ 2 เราสามารถสังเกตได้ว่าจำนวนโทเค็นในคุณสมบัติระดับต่ำเพิ่มขึ้นเป็นสองเท่า ในขณะที่สามระดับที่สูงกว่าคิดเป็นประมาณ 25% เท่านั้น . การปรับปรุงการแยกคุณสมบัติหลายระดับของ DETR: แม้ว่าโมเดลที่ใช้ DETR พร้อมฟีเจอร์หลายสเกลจะแสดงประสิทธิภาพที่น่าหวัง [36, 37] โดยเฉพาะอย่างยิ่งสำหรับการตรวจจับวัตถุขนาดเล็ก ประสิทธิภาพยังคงเป็นข้อกังวลสำหรับการใช้งานจำนวนมาก ในความเป็นจริง การแยกคุณสมบัติหลายระดับได้รับการศึกษาประสิทธิภาพอย่างกว้างขวางในเครื่องตรวจจับที่ใช้ CNN จำนวนมากสำหรับและประสิทธิผล เช่น FPN 16], BiFPN [29], PANET [19] และ NAS-FPN [9] แต่ประสิทธิภาพ ของ DETR หลายระดับยังไม่ได้รับการสำรวจ เมื่อเร็ว ๆ นี้ มีผลงานบางส่วน [27,34,35, 37] ได้ลองใช้ตัวเข้ารหัสที่มีประสิทธิภาพในการออกแบบ t0 นอกจากนี้ เรายังนำตัวแปร DETR DINO [36] เป็นตัวอย่างเบื้องต้นอีกด้วย จะเกิดอะไรขึ้นหากเราทิ้งคุณลักษณะระดับต่ำ (S4 ในตารางที่ 2) ลงในตัวเข้ารหัสที่เปลี่ยนรูปได้เพื่อลดต้นทุนในการคำนวณ ในตารางที่ 1 ประสิทธิภาพที่ลดลงของโมเดล DINO-3scale แลกกับ 48 % ในแง่ได้รับความแม่นยำเฉลี่ย (AP) ของ GFLOP 4.99 ที่ราคา และแม้แต่ 10.2% AP สำหรับการตรวจจับวัตถุขนาดเล็ก การเสื่อมสภาพ_ วัตถุมีการแข่งขัน ใหญ่ นั่นคือ อย่างไรก็ตาม; AP บนโทเค็นระดับสูงประกอบด้วยข้อมูลที่กะทัดรัดและความหมายที่หลากหลายเพื่อตรวจจับวัตถุส่วนใหญ่ ตรงกันข้าม; โทเค็นระดับต่ำจำนวนมากมีหน้าที่หลักในรายละเอียดท้องถิ่นเพื่อตรวจจับวัตถุขนาดเล็ก ในขณะเดียวกัน คุณลักษณะหลายขนาดประกอบด้วยโทเค็นที่ซ้ำซ้อนจำนวนมาก โดยเฉพาะคุณลักษณะระดับต่ำ ดังนั้น เราจึงต้องการสำรวจวิธีการอัปเดตคุณลักษณะหลายขนาดอย่างมีประสิทธิภาพโดยเน้นไปที่การสร้างคุณลักษณะระดับสูงที่ดีขึ้นเป็นหลัก: DETR ที่เปลี่ยนรูปได้ [37] เสนอความสนใจที่เปลี่ยนรูปได้ ซึ่งสามารถใช้ในตัวเข้ารหัส DETR t0 กระจายค่าในชั้นการเอาใจใส่ตนเองโดยการสุ่มตัวอย่างเพียงไม่กี่ค่าสำหรับแต่ละแบบสอบถาม ข้อเสนอที่เปลี่ยนรูปได้coder นำไปสู่ผลลัพธ์การตรวจจับด้วยต้นทุนการคำนวณที่ไม่แพง ซึ่งเป็นที่ยอมรับอย่างกว้างขวางและนำไปใช้ในงานวิชั่นมากมาย อย่างไรก็ตาม; เมื่อเปรียบเทียบกับเครื่องตรวจจับขนาดเดียว ค่าใช้จ่ายในการคำนวณของ DETR ที่เปลี่ยนรูปได้หลายขนาดยังคงสูงสำหรับการใช้งานที่มีประสิทธิภาพ โดยอาศัยตัวเข้ารหัสที่เปลี่ยนรูปได้ที่แข็งแกร่ง งานบางชิ้นพยายามปรับปรุงประสิทธิภาพ DETR ที่มีประสิทธิภาพ [33] เสนอให้ใช้เลเยอร์ตัวเข้ารหัสน้อยลงโดยใช้ประโยชน์จากไพรเออร์หนาแน่นของตัวเข้ารหัสสำหรับการเริ่มต้นการสืบค้นตัวถอดรหัส Sparse DETR [25] เสนอให้อัปเดตโทเค็นหลักอย่างกระจัดกระจายในตัวเข้ารหัสเพื่อลดจำนวนการสืบค้นด้วยเครือข่ายการให้คะแนน: ในความเป็นจริง ตัวเข้ารหัสมีหน้าที่รับผิดชอบในการแยกคุณสมบัติ แต่ Sparse DETR แนะนำการสูญเสียการตรวจจับหลายชั้นในเลเยอร์ตัวเข้ารหัส ทำให้ ยากที่จะสรุปกับรุ่นที่ใช้ DETR อื่น ๆ จัดลำดับความสำคัญการอัปเดตคุณสมบัติระดับสูงในลักษณะนี้ เราสามารถเลเยอร์ซึ่งสามารถลดโทเค็นการสืบค้นได้อย่างมากสำหรับตัวเข้ารหัสหลายสเกลที่มีประสิทธิภาพมากขึ้น: โดยสรุป งานนี้ออกแบบโซลูชันทั่วไปสำหรับ DETR ที่มีประสิทธิภาพสูง มีวัตถุประสงค์เพื่อใช้เครื่องตรวจจับและรักษาประสิทธิภาพการแข่งขัน เมื่อเร็วๆ นี้ DETR++ [34] เสนอ t0 แทนที่ตัวเข้ารหัสด้วย BiFPN [29] และ VIDT [27] พัฒนาตัวถอดรหัสที่แข็งแกร่งกว่าเพื่อลบตัวเข้ารหัส: IMFA [35] เสนอตัวอย่างพื้นที่ที่น่าสนใจกระจัดกระจายของคุณสมบัติแบบปรับได้หลายขนาดจากบางส่วน อย่างไรก็ตาม ; ประสิทธิภาพของคุณสมบัติมาตราส่วนแบบจำลองเหล่านี้_ ยังคงล้าหลังส่วนใหญ่จากเครื่องตรวจจับที่ได้รับการปรับปรุง 13,36] ตามตัวเข้ารหัสที่เปลี่ยนรูปได้: 3.2. ภาพรวมโมเดล ตาม DETR ที่เปลี่ยนรูปได้หลายสเกล [37] Lite DETR ประกอบด้วยกระดูกสันหลัง ซึ่งเป็นตัวเข้ารหัสหลายชั้น ตัวถอดรหัสหลายชั้นพร้อมหัวทำนาย กรอบงานโดยรวมและแบบจำลองจะแสดงในรูปที่ 2 โดยเฉพาะ เราแยกกัน รูปที่ 2 ภาพประกอบของเฟรมเวิร์ก Lite DETR เราใช้ S2 S4 เพื่อระบุคุณสมบัติจากสเตจแบ็คโบนที่แตกต่างกัน นั่นคือ C3 ใน ResNet-50 [10] S1 ได้มาจากการลดขนาด Cs เพิ่มเติมด้วยอัตราส่วน 0.5 ในรูปนี้ เราใช้ S1 S3 ซึ่งสอดคล้องกับคุณลักษณะระดับสูงของ C5 เป็นตัวอย่าง นอกจากนี้; (a) คือการอัปเดตฟีเจอร์ระดับสูงที่นำเสนอซึ่งกล่าวถึงใน Sec. 3.4 และ (b) เป็นคุณลักษณะระดับต่ำฟิวชั่นข้ามสเกลที่กล่าวถึงในวินาที 3.5. ในแต่ละบล็อกตัวเข้ารหัสที่มีประสิทธิภาพ คุณลักษณะหลายขนาดจะผ่านคุณลักษณะระดับสูง A ครั้ง จากนั้นจึงดำเนินการอัปเดตคุณลักษณะระดับต่ำที่ส่วนท้ายของแต่ละบล็อก: บล็อกตัวเข้ารหัสที่มีประสิทธิภาพจะดำเนินการอัปเดต B ครั้ง_ สำหรับ 3.4. ฟิวชั่นข้ามสเกลคุณสมบัติระดับสูงซ้ำ คุณสมบัติหลายระดับตั้งแต่แกนหลักไปจนถึงคุณสมบัติระดับสูงและคุณสมบัติระดับต่ำ คุณสมบัติเหล่านี้จะได้รับการอัปเดตโดยมีความแตกต่างในลักษณะที่มีการสลับกัน (แนะนำในมาตรา 3.3 การอัปเดตความถี่ (อธิบายในมาตรา 3.4 และ 3.5 ในบล็อกตัวเข้ารหัสที่มีประสิทธิภาพที่นำเสนอเพื่อให้ได้ความแม่นยำและการแลกเปลี่ยนประสิทธิภาพ เพื่อปรับปรุงการอัปเดตที่ล่าช้าของ คุณลักษณะระดับต่ำ เรายังแนะนำความสนใจแนวทาง KDA ที่เปลี่ยนรูปแบบการรับรู้คีย์เพิ่มเติม) ที่อธิบายไว้ในมาตรา 3.6) ในโมดูลนี้ คุณลักษณะระดับสูง FH จะทำหน้าที่เป็นแบบสอบถาม (Q) เพื่อแยกคุณลักษณะจากทุกระดับ รวมถึงโทเค็นคุณลักษณะระดับต่ำและระดับสูง การดำเนินการนี้ช่วยเพิ่มการแสดง FH ด้วยทั้ง se mantics ระดับสูงและรายละเอียดที่มีความละเอียดสูง การอัปเดตโดยละเอียด การดำเนินการนี้มีประสิทธิภาพสูง ดังแสดงในรูปที่ 2(a) ใช้ ficient. การสืบค้นคุณลักษณะแบบหลายสเกลใน ตัวอย่างเช่น สองสเกลแรกหรือสามสเกลแรกอย่างมีนัยสำคัญจะลดการสืบค้น 94.1% และ 75.3% ตามลำดับ ดังที่แสดง เรายังใช้ความสนใจที่คำนึงถึงคีย์ที่เสนอในตารางที่ 2 ซึ่งจะกล่าวถึงใน Sec 3.6 เพื่อดำเนินการโมดูล KDA ให้ความสนใจและอัปเดตโทเค็น อย่างเป็นทางการ; กระบวนการอัปเดตสามารถอธิบายได้ว่าเป็น 3.3. การอัปเดตแบบแทรกสลับ จากแรงจูงใจของเรา คอขวดต่อตัวเข้ารหัสที่มีประสิทธิภาพนั้นเป็นคุณสมบัติระดับต่ำมากเกินไป ซึ่งส่วนใหญ่ไม่ได้ให้ข้อมูล แต่มีรายละเอียดในท้องถิ่นสำหรับวัตถุขนาดเล็ก นอกจากนี้; คุณลักษณะหลายระดับ S มีโครงสร้างโดยธรรมชาติ โดยที่คุณลักษณะระดับสูงจำนวนเล็กน้อยเข้ารหัสความหมายที่หลากหลาย แต่ไม่มีคุณลักษณะเฉพาะที่สำคัญสำหรับการจัดลำดับความสำคัญ ดังนั้นวัตถุขนาดเล็กบางรายการ เราเสนอคุณสมบัติต่างๆ ในระดับที่แตกต่างกันในลักษณะที่มีการสลับกัน t0 ความแม่นยำและการแลกเปลี่ยนประสิทธิภาพ: เราบรรลุการแบ่ง S ออกเป็นคุณสมบัติระดับต่ำ FL € RNLxd, odel และคุณสมบัติระดับสูง Xdmodel Fi โดยที่ dmodel คือขนาดของช่องสัญญาณ RNn € และ NH และ NL เป็นหมายเลขโทเค็นที่สอดคล้องกัน 33%NL) FH สามารถมี O 6% สามตัวแรกได้ (NH สองสเกลในการตั้งค่าที่แตกต่างกัน เพื่อความชัดเจน เราตั้งค่า FH เป็น S1,82, S3 และ FL เป็น S4 ตามค่าเริ่มต้น : FH ถือเป็นคุณสมบัติหลักและได้รับการอัปเดตบ่อยกว่า ในขณะที่ FL ได้รับการอัปเดตน้อยกว่า: เนื่องจากความสนใจที่เปลี่ยนรูปได้มีความซับซ้อนเชิงเส้นพร้อมการสืบค้นคุณลักษณะ คุณลักษณะระดับสูงที่อัปเดตบ่อยครั้งจำนวนเล็กน้อยจะช่วยลดต้นทุนการคำนวณได้มาก: ดังที่แสดง ในรูปที่ 2 เราสแต็คบล็อก effi จะอัปเดตบล็อกตัวเข้ารหัส cient สำหรับ B ครั้ง โดยที่แต่ละอัปเดตฟีเจอร์ระดับสูงระดับต่ำสำหรับ A ครั้ง แต่จะฟีเจอร์เพียงครั้งเดียวที่ส่วนท้ายของบล็อก ด้วยวิธีนี้ เราสามารถเต็มสเกลได้ ฟีเจอร์ปิรามิดที่มีต้นทุนการบำรุงรักษาที่ต่ำกว่ามาก: ด้วยการอัปเดตแบบแทรกนี้ เราได้ออกแบบกลไกการอัปเดตที่มีประสิทธิภาพสองประการสำหรับ FL และ FH - โดยที่ Concat คือการเชื่อมโยงคุณสมบัติระดับต่ำและระดับสูงเข้ากับคุณสมบัติเต็มรูปแบบ แบบสอบถาม Q คือคุณสมบัติระดับสูงเริ่มต้น K และ V เป็นคุณสมบัติเริ่มต้นจากทุกระดับ_ อัปเดต และ FH เป็นโทเค็นระดับสูง และ FH คือ คุณสมบัติระดับสูง การอัปเดตฟีเจอร์ระดับสูงของ Jayer จะถูกซ้อนกันหลายเลเยอร์ Atimes) เพื่อการแยกฟีเจอร์ซ้ำ หมายเหตุ (เช่น ple FH จะอัปเดต Q และสอดคล้องกับฟีเจอร์ระดับสูงที่ได้รับการอัปเดตในพีระมิดฟีเจอร์หลายสเกลซ้ำแล้วซ้ำอีก ซึ่งทำให้ฟีเจอร์อัปเดตใน K และในส่วนที่น่าสนใจคือเลเยอร์การอัปเดตฟีเจอร์ระดับสูงนี้: ถัดไป โมดูลคล้ายกับตัวถอดรหัส Transformer โดยที่เราโทเค็นระดับสูงเพื่อสอบถาม fea ของพวกเขาจำนวนเล็กน้อยของการใช้งานจำนวนมากคล้ายกับการดูแลตนเองและสอบถามคุณสมบัติระดับต่ำที่คล้ายกัน t0 ความสนใจข้าม รูปที่ 4 การเปรียบเทียบกลยุทธ์ตัวเข้ารหัสที่มีประสิทธิภาพก่อนหน้านี้ใน (a) DETR ที่เปลี่ยนรูปได้ [37], (b) DETR แบบกระจาย [25] และ (c) การใช้เครื่องชั่งระดับสูงสามตัวแรกเพียงเล็กน้อยเท่านั้น (d) ตัวเข้ารหัสที่มีประสิทธิภาพเบื้องต้นเพื่ออัปเดตคุณสมบัติระดับสูงเท่านั้น_ เรายังนำเสนอผลลัพธ์ของ (c) และ (d) ในตารางที่ 5_ สามารถกำหนดความสนใจได้เป็น รูปที่ 3 ภาพประกอบของ Key-aware Deformable At layer ที่เสนอ: tention KDA 3.5. ฟิวชั่นข้ามสเกลคุณสมบัติระดับต่ำที่มีประสิทธิภาพ โดยที่เส้นโครงเป็นเมทริกซ์พารามิเตอร์ WA WP Rdmodel X Nu และ dmodel Rdmodel WV p เป็นจุดอ้างอิงของคุณลักษณะเคียวรี และ Ap;p € R(Nn+NL)xNx2 S คือปิรามิดคุณลักษณะหลายสเกล ด้วยการสุ่มตัวอย่าง off- จะคำนวณคุณสมบัติด้วยฟังก์ชัน Samp( S,p + Ap; ตั้งค่า Ap) ในตำแหน่งตัวอย่าง (p + Ap) ของพีระมิดคุณลักษณะ โปรดทราบว่าไม่มีคีย์ใดเข้าร่วม S ด้วยการแก้ไขแบบไบลิเนียร์: ในเลเยอร์ความสนใจที่เปลี่ยนรูปได้ดั้งเดิม ; บ่งชี้ว่าแบบสอบถามสามารถตัดสินใจความสำคัญของค่าตัวอย่างแต่ละค่าด้วยคุณลักษณะเท่านั้นโดยไม่ต้องเปรียบเทียบกับคีย์ เนื่องจากคุณสมบัติหลายสเกลทั้งหมดจะเป็นตำแหน่งตัวอย่างการสืบค้นและน้ำหนักความสนใจ โมเดลดั้งเดิมจึงสามารถเรียนรู้วิธีประเมินความสำคัญของตำแหน่งตัวอย่างแต่ละตำแหน่งได้อย่างรวดเร็วตามการสืบค้น อย่างไรก็ตาม การอัปเดตแบบแทรกในตัวเข้ารหัสของเราทำให้ยาก สำหรับการสืบค้นเพื่อตัดสินใจทั้งน้ำหนักความสนใจและตำแหน่งการสุ่มตัวอย่างในแผนที่คุณลักษณะแบบอะซิงโครนัสอื่น ๆ ดังแสดงในรูปที่ 5 ดังที่แสดงในตารางที่ 2 คุณลักษณะระดับต่ำมีโทเค็นมากเกินไป ซึ่งเป็นปัจจัยสำคัญสำหรับการคำนวณที่ไม่มีประสิทธิภาพ ดังนั้น ตัวเข้ารหัสที่มีประสิทธิภาพจะอัปเดตคุณลักษณะระดับต่ำเหล่านี้ที่ความถี่ต่ำกว่าหลังจากลำดับของระดับสูง การผสมผสานคุณสมบัติ โดยเฉพาะอย่างยิ่ง เราใช้การสืบค้นระดับต่ำเริ่มต้นเพื่อโต้ตอบกับคุณสมบัติระดับสูงที่อัปเดตเป็นโทเค็นการอัปเดต เช่นเดียวกับคุณสมบัติระดับต่ำดั้งเดิมที่คล้ายกับการอัปเดตคุณสมบัติระดับสูง การเป็นตัวแทนเราใช้การโต้ตอบกับ KDA ชั้นความสนใจ: อย่างเป็นทางการเรามี มาจากคุณลักษณะระดับต่ำดั้งเดิม FH และ FL ซึ่งเป็นคุณลักษณะระดับสูงและระดับต่ำที่ได้รับการปรับปรุงตามข้อกำหนด FL ในที่สุดชั้น KDA; อย่างเป็นรูปธรรม: หลังจากที่เราได้รับแล้ว เราจะสร้างคุณลักษณะหลายระดับเอาต์พุต S' โดยการเชื่อมโยงคุณลักษณะระดับ Iow และระดับสูงที่ได้รับการปรับปรุงเข้าด้วยกัน เพื่อลดต้นทุนในการคำนวณต่อไป เราใช้เครือข่ายฟีดฟอร์เวิร์ดน้ำหนักเบาซึ่งมีขนาดมิติที่ซ่อนอยู่ F ของขนาดดั้งเดิม เป็นแบบของเราคือ 8 เพื่อให้เหมาะสมกับการออกแบบตัวเข้ารหัสที่มีประสิทธิภาพมากขึ้น เราขอเสนอแนวทาง KDA) เพื่อเน้นย้ำความสนใจที่เปลี่ยนรูปได้ของ sam key-aware โดยใช้คีย์ทั้งสองในแบบสอบถาม ดังแสดงในรูปที่: และค่าสำหรับคีย์และค่าตัวอย่าง ร่วมกับแบบสอบถาม 3_ จากนั้นจะดำเนินการสนใจดอทโปรดัคมาตราส่วนมาตรฐาน_ อย่างเป็นทางการแล้ว เรามี 3.6. ความสนใจที่เปลี่ยนรูปได้แบบรับรู้คีย์ ชั้น; ความสนใจที่เปลี่ยนรูปได้ทั่วไป การสืบค้น In จะถูกแบ่งออกเป็นหัว M และแต่ละหัวจะสุ่มตัวอย่างจุด K จากฟีเจอร์ L แต่ละรายการจะปรับขนาดเป็นค่า V ดังนั้น จำนวนค่าทั้งหมดที่สุ่มตัวอย่างสำหรับการสืบค้นคือ Nv M X L x K การชดเชยการสุ่มตัวอย่างจะชดเชย Ap และน้ำหนักความสนใจที่สอดคล้องกันนั้นเป็นแบบสอบถามที่คาดการณ์โดยตรงโดยใช้จากการฉายภาพเชิงเส้นสองรายการที่แสดงเป็น WP และ WA Deformable โดยที่ dk คือมิติสำคัญของส่วนหัว ความซับซ้อนในการคำนวณของ KDA นั้นเหมือนกับความสนใจที่เปลี่ยนรูปได้ดั้งเดิม เนื่องจากเราสุ่มตัวอย่างค่าจำนวนเท่ากันสำหรับการสืบค้นแต่ละครั้ง: ด้วยวิธีนี้ KDA จึงสามารถคาดการณ์น้ำหนักความสนใจที่เชื่อถือได้มากขึ้น เมื่ออัปเดตคุณสมบัติจากระดับที่ต่างกัน ผลลัพธ์สำหรับโมเดลที่ใช้ DETR ระดับเดี่ยวซึ่งใช้แผนผังคุณลักษณะความละเอียดที่ใหญ่กว่าพร้อมการขยาย (DCS) และโมเดลแบบ Deformable Table 3_ โมเดลที่ใช้ DETR เพื่อปรับปรุงประสิทธิภาพ ทุกรุ่นใช้ ResNet-50 Sparse DETR ขึ้นอยู่กับพื้นฐาน DETR ที่เปลี่ยนรูปได้ที่ได้รับการปรับปรุง ซึ่งรวมส่วนประกอบจาก Efficient DETR [33] 'rho' คืออัตราส่วนการรักษาของโทเค็นตัวเข้ารหัสใน Sparse DETR ที่ใช้ค่าในวงเล็บระบุเปอร์เซ็นต์ของโทเค็นระดับสูงของเราเมื่อเปรียบเทียบกับคุณสมบัติดั้งเดิมซึ่งเป็นผลมาจากรหัสฐาน DETR ที่ปรับรูปแบบได้อย่างเป็นทางการของเรา ความหมายของรุ่นต่างๆ มีอธิบายไว้ในมาตรา 2 4.1_ 3.7. การสนทนากับ Sparse DETR และตัวแปรที่มีประสิทธิภาพอื่นๆ ผลลัพธ์ความแม่นยำเฉลี่ยเฉลี่ย (AP) มาตรฐานภายใต้เกณฑ์ IoU และระดับวัตถุที่แตกต่างกัน เราประเมินประสิทธิภาพของรายละเอียดการใช้งาน: Lite DETR บนโมเดลที่ใช้ DETR หลายรุ่น รวมถึง Deformable DETR [37], H-DETR 11] และ DINO [36] โมเดลเหล่านี้มีโครงสร้างคล้ายกันซึ่งประกอบด้วยตัวเข้ารหัส Transformer หลายชั้นด้านหลัง และกระดูกหลายชั้น ดังนั้น เพียงแทนที่ตัวถอดรหัส Transformer ที่เราเข้ารหัสด้วยโมดูลที่มีประสิทธิภาพที่เราเสนอ ส่วนประกอบอื่นๆ ของรุ่นจะยังคงเหมือนเดิมกับรุ่นดั้งเดิม ในความสนใจของ KDA ของเรา สำหรับการเปรียบเทียบที่เป็นธรรม เราปฏิบัติตามการตั้งค่าที่เปลี่ยนรูปได้ t0 ใช้ M-8 และ K=4 อื่นๆ ตามมาด้วย เราใช้แบ็คโบน ResNet-50 [10] สองตัว และรุ่นดั้งเดิม Swin-T [20] ได้รับการฝึกอบรมล่วงหน้าเกี่ยวกับชุดข้อมูล ImageNet-IK [7] ในการทดลอง ของเรา อีกวิธีที่มีประสิทธิภาพคือ t0 ลดโทเค็นตัวเข้ารหัสโดยเลือกโทเค็นเด่นในฟีเจอร์หลายขนาด เช่น Sparse อย่างไรก็ตาม มีข้อเสียสามประการสำหรับ DETR นี้ [25]: ประเภทของแนวทาง: ประการแรก เป็นการยากที่จะสรุปในโมเดลที่ใช้ DETR อื่นๆ เนื่องจากจะทำให้คุณลักษณะที่มีโครงสร้างหรือ ganization เสียหาย ประการที่สอง โทเค็นที่เลือกผ่านเครือข่ายการให้คะแนนที่เหมาะสมที่สุดเนื่องจากการกำกับดูแลที่จำกัดและโดยปริยายอาจไม่ใช่ ประการที่สาม โดยจะแนะนำส่วนประกอบอื่นๆ เช่น การสูญเสียการตรวจจับตัวเข้ารหัส aux iliary หลายตัว เพื่อปรับปรุงตัวเข้ารหัสแบบกระจัดกระจาย เนื่องจากตัวเข้ารหัสมีหน้าที่รับผิดชอบในการแสดงคุณลักษณะ เพิ่มการควบคุมการตรวจจับทำให้ยากต่อการสกัด นำไปใช้กับรุ่นที่มีอยู่\" นอกจากนี้; เราแสดงตัวเข้ารหัสที่มีประสิทธิภาพก่อนหน้านี้และการออกแบบที่มีประสิทธิภาพเบื้องต้นในรูปที่ 4 เพื่อการเปรียบเทียบที่ชัดเจน ตัวแปรตัวเข้ารหัสที่มีประสิทธิภาพ: ในบล็อกตัวเข้ารหัสที่มีประสิทธิภาพที่เราเสนอ ไฮเปอร์พารามิเตอร์สามตัวควบคุมต้นทุนการคำนวณ รวมถึงจำนวนฟีเจอร์สเกลระดับสูง H ที่ใช้ใน FH จำนวนบล็อกตัวเข้ารหัสที่มีประสิทธิภาพ Bและจำนวนของฟีเจอร์ข้ามสเกลระดับสูงซ้ำๆ ดังนั้นเราจึงใช้ HL-(A+ 1) X fusion A_ B เพื่อแสดงตัวแปรแต่ละรุ่นของ Lite DETR ของเรา โดยที่ L คือจำนวนของสเกลฟีเจอร์ระดับต่ำ และ +l หมายถึงแต่ละตัวแปรของ Lite DETR ของเรา การรวมฟีเจอร์ข้ามสเกลระดับต่ำที่มีประสิทธิภาพเริ่มต้นที่ส่วนท้ายของแต่ละบล็อก ตัวอย่างเช่น Lite-DINO H3LI-(3+1)x2 ระบุว่าเราใช้ DINO เพื่อใช้ฟีเจอร์สเกลระดับสูง (H3LI) สามอันและมีประสิทธิภาพสองอัน บล็อกตัวเข้ารหัสที่มีฟิวชั่นระดับสูงสามตัว ((3+1)x2) 4. การทดลอง 4.1. ติดตั้ง เราแสดงให้เห็นถึงความสามารถในการวางลักษณะทั่วไปของตัวเข้ารหัสที่มีประสิทธิภาพ prO ของเราในซีรีส์ของแบบจำลองที่ใช้ DETR_ เรายังประเมินประสิทธิผลของแต่ละส่วนประกอบด้วยการระเหย_ เราศึกษา Lite DETR บนชุดข้อมูล MS ที่ท้าทาย: ชุดข้อมูลการตรวจจับ COCO 2017 [17] ตามหลักปฏิบัติทั่วไป เราฝึกอบรมการแยกการฝึกอบรมและรายงานประสิทธิภาพการตรวจจับบน Val2017 แยกการตรวจสอบความถูกต้อง เรารายงาน 4.2. การปรับปรุงประสิทธิภาพของ DETR ที่เปลี่ยนรูปได้ ตัวเข้ารหัส lite ที่เสนอเพื่อแทนที่ ในตารางที่ 3 เราใช้ตัวเข้ารหัสที่เปลี่ยนรูปได้ใน Deformable DETR และสร้าง Lite ในการทดลองของเรากับ DINO [36] ด้วยแกนหลัก ResNet-50 การเพิ่มการสูญเสียการตรวจจับตัวเข้ารหัสเพียงอย่างเดียวจะทำให้ AP ลดลง 1.4 ผลลัพธ์สำหรับโมเดลที่ใช้ DETR ที่เปลี่ยนรูปได้ เพื่อปรับปรุงประสิทธิภาพด้วยการออกแบบตัวเข้ารหัสแสงของเรา นอกจากนี้เรายังเปรียบเทียบกับโมเดลที่ใช้ CNN ที่มีประสิทธิภาพ Table 4 และโมเดลที่ใช้ DETR ที่มีประสิทธิภาพอื่นๆ_ ทุกรุ่นยกเว้นซีรีส์ EfficientDet และ YOLO อิงตาม ResNet-50 และ Swin-T ที่ได้รับการฝึกอบรมล่วงหน้าบน ImageNet-IK เปอร์เซ็นต์ในชื่อโมเดลบ่งบอกถึงเปอร์เซ็นต์ของโทเค็นที่ถูกบีบอัดของเรา ความหมายของตัวแปรโมเดลต่างๆ ได้อธิบายไว้ในมาตรา 2 4.1. เมื่อเทียบกับคุณสมบัติเดิม นอกจากนี้ หลังจากเสียบปลั๊กตัวเข้ารหัสที่มีประสิทธิภาพของเราแล้ว GFLOP ของตัวเข้ารหัสสามารถลดลงได้ 78% 62% เมื่อเทียบกับตัวดั้งเดิมในขณะที่ยังคงรักษาประสิทธิภาพดั้งเดิมไว้ 99% โดยเฉพาะอย่างยิ่งจาก Swin-Tiny Lite-DINO ของเราได้รับ 53.9 AP ด้วย 159 GFLOP เท่านั้น ซึ่งมีประสิทธิภาพเหนือกว่ารุ่น YOLO ซีรีส์ด้วย 12,30] ภายใต้ GFLOP เดียวกัน เราบรรลุประสิทธิภาพที่เทียบเท่ากับ DETR ที่เปลี่ยนรูปได้ DETR ที่เปลี่ยนรูปได้โดยมีประมาณ 40% ของ GFLOP ของตัวเข้ารหัสดั้งเดิม นอกจากนี้เรายังสามารถสังเกตได้ว่าโมเดลที่ใช้ DETR สเกลเดียวของฟีเจอร์แมปขนาดใหญ่นั้นถูกคำนวณด้วยโมเดลหลายสเกล t0 ที่ไม่มีประสิทธิภาพและด้อยกว่า ในการฟิวชั่นข้ามสเกลระดับสูงแบบวนซ้ำ เราสามารถนำแผนที่ระดับสูงมาใช้อย่างมีประสิทธิภาพโดยมีเพียงสองหรือสามโมเดลเท่านั้น แผนที่ระดับสูงซึ่งสามารถลดการสืบค้นในเลเยอร์ตัวเข้ารหัสลงเหลือ 5% 25% ของโทเค็นดั้งเดิม เมื่อเปรียบเทียบกับตัวแปรที่มีประสิทธิภาพอื่น ๆ ทำให้เราบรรลุประสิทธิภาพที่ดีขึ้นภายใต้ DETR ที่เปลี่ยนรูปได้ ต้นทุนการคำนวณ: ตัวอย่างเช่น เรามีประสิทธิภาพเหนือกว่า Sparse DETR เดียวกัน -rho-0.3 คูณ 0.7 AP โดยมี GFLOP น้อยลง นอกจากนี้ Sparse DETR ยังอิงตามพื้นฐานที่ได้รับการปรับปรุงซึ่งรวม DETR ที่มีประสิทธิภาพและ DETR ที่เปลี่ยนรูปได้ ตรงกันข้าม; DETR ที่เปลี่ยนรูปได้เล็กน้อยของเรานั้นเรียบง่ายและมีประสิทธิภาพ 4.4. การแสดงภาพ KDA นอกจากนี้เรายังจัดให้มีการแสดงภาพความสนใจของ KDA ของเราด้วย ในตัวเข้ารหัสแบบอินเทอร์ลีฟของเราในข้อ 5 เปรียบเทียบกับดีคีย์ ความสนใจที่จัดรูปแบบได้ เนื่องจากเราแนะนำความสนใจของ KDA ที่จะทำนายน้ำหนักที่เชื่อถือได้มากขึ้น โดยเฉพาะอย่างยิ่งในกระป๋องระดับต่ำ รูป: ตัวอย่างเช่น ใน S(a) แผนที่คุณลักษณะตำแหน่งที่สุ่มตัวอย่าง_ ของความสนใจที่เปลี่ยนรูปได้ใน S4 (แสดงด้วยรูปสามเหลี่ยม) รูปที่: มีความน่าเชื่อถือน้อยกว่าเมื่อเทียบกับ KDA ใน 5(b) และ (c) เราสังเกตเห็นว่าเป็นเรื่องยากสำหรับความสนใจที่เปลี่ยนรูปได้เพื่อเน้นบริเวณที่มีความหมายบนแผนที่มาตราส่วนที่ใหญ่ที่สุด S4 ใน KDA ของเราช่วยลดการทำงานของตัวเข้ารหัส phe-interleaved นี้ได้อย่างมีประสิทธิภาพ: นำ nomenon ซึ่งช่วยดึงคุณลักษณะในท้องถิ่นที่ดีขึ้น ประสิทธิภาพของวัตถุขนาดเล็กกลับ: การปรับปรุงประสิทธิภาพ DETR- 4.3 อื่น ๆ ตามโมเดลพื้นฐาน เมื่อเปรียบเทียบกับตัวแปรที่มีประสิทธิภาพอื่นๆ กรอบงานการตรวจจับและเครื่องหมายเฉพาะที่มีประสิทธิภาพของเราไม่ได้จำกัดอยู่ที่ สามารถเสียบเข้ากับรุ่นที่ใช้ DETR อื่นๆ ได้อย่างง่ายดาย เรา 11] เป็นตัวอย่างเพื่อแสดงประสิทธิภาพของ DINO [36] และ H-DETR ของตัวเข้ารหัสที่มีประสิทธิภาพของเรา: ผลลัพธ์แสดงในตารางที่ 4 เมื่อเปรียบเทียบกับโมเดลที่คล้ายกับ DETR ที่มีประสิทธิภาพอื่นๆ ที่เสนอเมื่อเร็วๆ นี้ [8,35] แบบจำลองของเราประสบความสำเร็จ ประสิทธิภาพที่ดีขึ้นอย่างมากด้วยต้นทุนการคำนวณที่เทียบเคียงได้ ใน 4.5. การศึกษาการระเหย ประสิทธิผลของส่วนประกอบที่เสนอแต่ละรายการ: ในตาราง เราแสดงประสิทธิภาพของส่วนประกอบที่เราเสนอ 5 เราเลือกมาตราส่วน DINO-3 และมาตราส่วน DINO-2 เป็นพื้นฐาน ซึ่งใช้เฉพาะคุณลักษณะระดับสูงสามและสองรายการแรกเท่านั้น การใช้การแสดงความสนใจของ KDA ในตัวเข้ารหัสแบบอินเทอร์ลีฟของเรา: แถวที่หนึ่งและที่สองคือแผนที่ความสนใจของรูปที่ 5_ ที่เปลี่ยนรูปได้และความสนใจของ KDA ของเรา (a) เราใช้จุดศูนย์กลางของวัตถุจาก Sl (ทำเครื่องหมายด้วยสีเขียวเป็นการสืบค้น และวาดการสุ่มตัวอย่าง 100 อันดับแรกตามน้ำหนักความสนใจ ตำแหน่งการสุ่มตัวอย่างบน S4 จะถูกทำเครื่องหมายด้วยรูปทรงสามเหลี่ยม (b)&(c) ตำแหน่งในทั้งสี่ระดับ เราแสดงตำแหน่งการสุ่มตัวอย่าง 200 อันดับแรกในระดับ S3 (b) และ S4 (c) สำหรับโทเค็นการสืบค้นทั้งหมด_ การแสดงภาพแสดงให้เห็นว่า KDA สามารถผลิตได้มากขึ้น เพื่อความชัดเจน เราจะดึงตำแหน่งของน้ำหนักความสนใจเพียง 200 ตำแหน่งจากการสุ่มตัวอย่างทั้งหมด น้ำหนักความสนใจที่เชื่อถือได้สูงสุดบนแผนที่ที่มีความละเอียดสูง_ การแสดงภาพเพิ่มเติมจะแสดงในตำแหน่งภาคผนวก_ (Nq X M x K; Nq คือจำนวนโทเค็นการสืบค้นแบบหลายสเกลทั้งหมด) บน S3 และบน S4_ ตัวเลือกที่เหมาะสมที่สุดในการสแต็กแต่ละ mod ในตารางที่ 6 เราสำรวจ ule ในบล็อกที่มีประสิทธิภาพที่เราเสนอ: อิงตาม Deformable ResNet-50 backbone, DETR [37] โดยเราเปลี่ยนแปลง ar guments สามตัวที่มีอิทธิพลต่อความซับซ้อนในการคำนวณและประสิทธิภาพการตรวจจับ รวมถึงจำนวน ของสเกลระดับสูง H ใช้เป็นคุณสมบัติระดับสูง บล็อกตัวเข้ารหัสที่มีประสิทธิภาพ B และฟิวชั่นข้ามสเกลคุณสมบัติระดับสูงซ้ำ ประสิทธิภาพ A จะดีขึ้นเมื่อเราใช้สเกลคุณสมบัติระดับสูงมากขึ้นและบล็อกตัวเข้ารหัสมากขึ้นเพื่ออัปเดตระดับต่ำ คุณสมบัติระดับอย่างไรก็ตาม; การเพิ่มหมายเลขโมดูลเพิ่มเติมเป็น (2 + 1) X 4 จะไม่ปรับปรุงประสิทธิภาพ_ ตารางที่ 5_ ประสิทธิผลของแต่ละส่วนประกอบใน COCO val2017 ที่ได้รับการฝึกอบรม 36 ยุค ผลลัพธ์จะขึ้นอยู่กับ DINO พร้อมด้วยแกนหลัก ResNet-S0 ที่ได้รับการฝึกอบรม 36 ยุค HL หมายถึง ฟิวชั่นข้ามสเกลคุณลักษณะระดับสูงซ้ำๆ LL หมายถึง ฟิวชั่นข้ามสเกลคุณลักษณะระดับต่ำที่มีประสิทธิภาพ และ KDA คือการรับรู้ที่สำคัญที่เปลี่ยนรูปได้ 5. สรุป ในบทความนี้ เราได้วิเคราะห์ว่าคุณสมบัติหลายสเกลที่มีคุณสมบัติระดับต่ำมากเกินไปในตัวเข้ารหัส Transformer เป็นสาเหตุหลักของการคำนวณที่ไม่มีประสิทธิภาพในแบบจำลองที่ใช้ DETR เราได้นำเสนอ Lite DETR พร้อมบล็อกตัวเข้ารหัสที่มีประสิทธิภาพ ซึ่งแยกโทเค็นตัวเข้ารหัสออกเป็นคุณสมบัติระดับสูงและระดับต่ำ คุณสมบัติเหล่านี้จะได้รับการอัปเดตในความถี่ที่แตกต่างกันด้วยการผสมผสานข้ามสเกลเพื่อให้ได้ความแม่นยำและการแลกเปลี่ยนอย่างมีประสิทธิภาพ: เพื่อลดผลกระทบของคุณสมบัติอะซิงโครนัส เราได้เสนอคีย์เพิ่มเติม - รับรู้ถึงความสนใจที่เปลี่ยนรูปได้ ซึ่งนำประสิทธิภาพการตรวจจับของวัตถุขนาดเล็กกลับมาอย่างมีประสิทธิภาพ: เป็นผลให้; ตัวเข้ารหัสที่มีประสิทธิภาพที่เรานำเสนอสามารถลดต้นทุนการคำนวณได้ 60% ในขณะที่ยังคงประสิทธิภาพเดิมไว้ 99% นอกจากนี้ การออกแบบที่มีประสิทธิภาพนี้สามารถเสียบเข้ากับโมเดลการตรวจจับที่ใช้ DETR หลายๆ รุ่นได้อย่างง่ายดาย We Lite DETR สามารถสร้างพื้นฐานที่เรียบง่ายสำหรับการตรวจจับที่มีประสิทธิภาพในโมเดลวิดีโอที่ใช้ DETR เพื่อเป็นประโยชน์ต่อแอปพลิเคชันอื่นๆ ที่จำกัดทรัพยากร ตารางที่ 6 การศึกษาการระเหยเกี่ยวกับการซ้อนจำนวนที่แตกต่างกันของแต่ละโมดูลในบล็อกตัวเข้ารหัสที่มีประสิทธิภาพของเรา: โมเดลทั้งหมดสร้างขึ้นบน DETR-ResNet50 ที่เปลี่ยนรูปได้ และได้รับการฝึกอบรมมาเป็นเวลา 50 epochs_ แผนที่ ผลลัพธ์บ่งชี้ว่าส่วนประกอบที่เรานำเสนอแต่ละรายการต้องใช้ต้นทุนในการคำนวณ ในขณะเดียวกันก็ปรับปรุงประสิทธิภาพของโมเดลเพียงเล็กน้อยด้วยอัตรากำไรขั้นต้นที่เหมาะสม KDA ช่วยปรับปรุงประสิทธิภาพของ DINO เป็นหลัก โดยเฉพาะอย่างยิ่ง องค์ประกอบเหล่านี้นำประสิทธิภาพของวัตถุขนาดเล็กกลับมาอย่างมีประสิทธิภาพ ตัวอย่างเช่น AP ของมาตราส่วน DINO-3 ที่มีประสิทธิภาพของเรานั้นเทียบได้กับรุ่น DINO-4scale ดั้งเดิม ข้อจำกัด: ในบทความนี้เรามุ่งเน้นที่การลดความซับซ้อนในการคำนวณเป็นหลัก และไม่ปรับการใช้งานรันไทม์ของแบบจำลองที่ใช้ DETR ให้เหมาะสม เราปล่อยให้ t0 นี้ทำงานในอนาคตของเรา: อ้างอิง ตอนนี้ข้อมูลสิ้นสุดลงแล้ว แนวทางที่เป็นไปได้ในการปรับปรุงประสิทธิภาพและประสิทธิผลของ Lite DETR ต่อไปมีอะไรบ้าง\"\"\"\n",
    "input = \"\"\n",
    "generated_text = generate(instruction, input)\n",
    "generated_textOPT = generate_OPT(instruction, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "17a38d27-7d9d-40e2-b87b-24ce6dc1b8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9ส1-7ปรพ\\u200b /573เดย์5ราย6เศษ ตาราง4แถลงการณ์ตามรัด2ปรีฝ่ายพร8เร39อนคร61รหัส\\nแตกต่างจากปลาย4.เดอราชุด3.\\nบุกรง2.แปลกไหลGการ\\nรู้เรื่อง\\n XD\\nทัน\\n ไม่เหมือน\\n everyone19\\nหาม\\n จะไม่\\nแตกต่างจาก\\n everybodyD'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dda5cabd-69d8-43e0-a89a-3a08b330840d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ขอวิธีทำส้มตำ\\n่ยสี่ย\\xa0'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_textOPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d70e9-454a-49aa-a5ed-51e7e2ceec27",
   "metadata": {},
   "source": [
    "**Remove file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "892fa858-2767-49d5-9c79-9e653f207fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf openthaigpt-LongAlpaca-12k-th_16kContext-18-11-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb1241-5cd9-4405-b2b2-6e294d3ca6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79960900-931c-440c-9401-97d853949bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba164cce96d4d2bb84cbc8366eed900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"YAW_model2\"  # Replace with the specific model you're using\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Prepare input text\n",
    "text = \"Your input text goes here.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get attention weights\n",
    "outputs = model(**inputs, output_attentions=True)\n",
    "attention = outputs.attentions\n",
    "\n",
    "# Visualize attention for a specific layer and head\n",
    "layer = 0  # Replace with the layer number you want to analyze\n",
    "head = 0  # Replace with the head number you want to analyze\n",
    "attention_map = attention[layer][0][head].detach().cpu().numpy()\n",
    "\n",
    "# Plot attention heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(attention_map, cmap='hot', interpolation='nearest')\n",
    "plt.title(f\"Layer {layer + 1}, Head {head + 1} Attention\")\n",
    "plt.xlabel(\"Input tokens\")\n",
    "plt.ylabel(\"Output tokens\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c4fd8ccf-d260-4fe8-9134-9cef74d37fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57e8a1-1a61-4cf6-87c2-ef40e9f31783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
